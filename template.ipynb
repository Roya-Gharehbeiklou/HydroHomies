{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HydroHomies Plots\n",
    "In this notebook, the plots, figures and also some explanations or details about each of them are being presented.  \n",
    "\n",
    "To clarify, plaase fallow this order:\n",
    "- Title for each plot is mandatory\n",
    "- Analysis must be written \n",
    "- Address of data should be mentioned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in all our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "with open('config.yaml') as stream:\n",
    "    config = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison of Dehydration and control of one person**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanations: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "code1"
    ]
   },
   "source": [
    "### Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_digit_span(raw_df):\n",
    "    # Select the sequence length data from the raw data and create a dataframe\n",
    "    seq_length_df = raw_df[raw_df[1].astype(str).str.match(r'\\d+')]\n",
    "    seq_length_df\n",
    "\n",
    "    # Get the value of the longest sequence remebered\n",
    "    longest = seq_length_df[2]\n",
    "    longest = longest.tolist()\n",
    "\n",
    "    # Get the number of errors made\n",
    "    error_number = seq_length_df[3]\n",
    "    error_number = error_number.tolist()\n",
    "\n",
    "    click_stim_df = raw_df[raw_df[1]=='clickedStim']\n",
    "    click_stim_df.size\n",
    "\n",
    "    clicks_observed = click_stim_df.count(axis=1) - 2 \n",
    "    clicks_observed = clicks_observed.tolist()\n",
    "\n",
    "    clicks_expected =  pd.to_numeric(longest) + 1\n",
    "    clicks_expected = clicks_expected.tolist()\n",
    "\n",
    "    clean_data = pd.DataFrame(data ={'seq length':longest,\n",
    "                        'errors': error_number,\n",
    "                        'clicks expected': clicks_expected,\n",
    "                        'clicks observed':clicks_observed})\n",
    "    \n",
    "    return clean_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def create_merged_df(config_dict, test_name):\n",
    "     # selects only the files we want to use\n",
    "    files = {name: file for name, file in config_dict.items() if re.search(test_name, name)} \n",
    "    # read the files \n",
    "    for test, file in files.items():\n",
    "        df_dict = pd.read_excel(file, sheet_name=None, header=None)\n",
    "        for session, df in df_dict.items():\n",
    "            # extracting the participant name, type name and repeat number\n",
    "            participant = test.split('_')[-1]\n",
    "            type, repeat = session.split('_')\n",
    "            # inserting the repeat, type, participant columns\n",
    "            df.insert(0, 'repeat', repeat)\n",
    "            df.insert(0, 'type', type)\n",
    "            df.insert(0, 'participant', participant)\n",
    "            # concatenate if df_all exists\n",
    "            try:\n",
    "                df_all = pd.concat([df_all, df])\n",
    "            except UnboundLocalError:\n",
    "                df_all = df\n",
    "    \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verbal_fluency = create_merged_df(config, 'verbal')\n",
    "df_flanker = create_merged_df(config, 'flanker')\n",
    "df_digit_span = create_merged_df(config, 'digit_span')\n",
    "df_stroop = create_merged_df(config, 'stroop')\n",
    "df_stop_signal = create_merged_df(config, 'stop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison of Dehydration of all participants**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanations: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison of Rehydration of all participants**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanations: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b91fa5cffef32cb10787a50fea9666676a7951181e01280b4644cd70c964bf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
