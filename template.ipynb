{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HydroHomies Plots\n",
    "In this notebook, the plots, figures and also some explanations or details about each of them are being presented.  \n",
    "\n",
    "To clarify plots, please follow this order:\n",
    "- Title for each plot is mandatory\n",
    "- Analysis must be written \n",
    "- legends are manedatory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.transform import dodge, factor_cmap\n",
    "from bokeh.models import ColumnDataSource, FactorRange, Whisker, Range1d\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()\n",
    "\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "\n",
    "import plotting_functions as pf\n",
    "\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as stream:\n",
    "    config = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "code1"
    ]
   },
   "source": [
    "### Cleaning (Digit Span Raw Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_digit_span(raw_df):\n",
    "    '''\n",
    "    Function to clear the raw digit span results obtained from the online test. \n",
    "    It keeps the rows and columns that are informative, and makes some basic \n",
    "    operations to obtain informative variables.\n",
    "    \n",
    "    Arguments:\n",
    "    raw_df: Dataframe obtained after reading the digitspan excel file with the \n",
    "    results.\n",
    "\n",
    "    Returns:\n",
    "    A clean and processed dataframe.\n",
    "    \n",
    "    Author:\n",
    "    Karina Diaz \n",
    "    '''\n",
    "    # Select the sequence length data from the raw data and create a dataframe\n",
    "    seq_length_df = raw_df[raw_df[1].astype(str).str.match(r'\\d+')]\n",
    "\n",
    "    # Get the value of the longest sequence remembered. Is the column with index 2\n",
    "    longest = seq_length_df[2]\n",
    "    longest = longest.tolist()\n",
    "\n",
    "    # Get the number of errors made. Is the column with index 3\n",
    "    error_number = seq_length_df[3]\n",
    "    error_number = error_number.tolist()\n",
    "\n",
    "    # Select the rows with the click stimulus data\n",
    "    click_stim_df = raw_df[raw_df[1]=='clickedStim']\n",
    "    click_stim_df.size\n",
    "\n",
    "    # Calculate the number of clicks made by the participant.\n",
    "    clicks_observed = click_stim_df.count(axis=1) - 3 \n",
    "    # 3 is subtracted because there are 3 non-informative values in the data \n",
    "    # that should not be taken into account.\n",
    "    clicks_observed = clicks_observed.tolist()\n",
    "\n",
    "    # Calculate the number of clicks that the participant should have made\n",
    "    clicks_expected =  pd.to_numeric(longest) + 1\n",
    "    clicks_expected = clicks_expected.tolist()\n",
    "\n",
    "    # Create a new dataframe with all the values calculated above\n",
    "    clean_data = pd.DataFrame(data ={'seq length':longest,\n",
    "                        'errors': error_number,\n",
    "                        'clicks expected': clicks_expected,\n",
    "                        'clicks observed':clicks_observed})\n",
    "\n",
    "    # Return the new dataframe\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Integration For Each Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function is created to get all the data in dataframes. The data of each test (so of all participant) is merged/concatenated to get a big dataframe, which can easily used later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merged_df(config_dict):\n",
    "    \"\"\"\n",
    "    Reads all of the files and creates a dataframe from it.\n",
    "    It then concatenates each dataframe according to the test, \n",
    "    to obtain one big dataframe per test (and one health data)\n",
    "\n",
    "    Args:\n",
    "        config_dict (dict): dictionary with all of the filepaths\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary with all the merged dataframes, \n",
    "              where the key is the file name and the value\n",
    "              the merge dataframe\n",
    "              \n",
    "    Author(s):\n",
    "        Job Maathuis\n",
    "        Hooman Bardo\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "\n",
    "    # read the files \n",
    "    for test, file in config_dict.items():\n",
    "        df_dict = pd.read_excel(file, sheet_name=None, header=None)\n",
    "\n",
    "        for session, df in df_dict.items():\n",
    "\n",
    "            # extracting the participant name and type name\n",
    "            participant = test.split('_')[-1]\n",
    "            test_name = test.split('_')[0]\n",
    "\n",
    "            # extracting repeat number and making its column except for personal health data\n",
    "            try:\n",
    "                type, repeat = session.split('_')\n",
    "                df.insert(0, 'repeat', repeat)\n",
    "\n",
    "            # healht data has a different structure, solving by taking session number\n",
    "            except ValueError:\n",
    "                type = session\n",
    "\n",
    "            # Running function to clean digit span data\n",
    "            if test_name == 'digit':\n",
    "                df = clean_digit_span(df.iloc[3:])\n",
    "                df.insert(0, 'repeat', repeat)\n",
    "            \n",
    "            # verbal fluency test contains header\n",
    "            elif test_name =='verbal':\n",
    "                df = df.iloc[1:]\n",
    "\n",
    "            # inserting the type and participant columns\n",
    "            df.insert(0, 'type', type)\n",
    "            df.insert(0, 'participant', participant)\n",
    " \n",
    "            # concatenating data frames of each test\n",
    "            if test_name not in data_dict:\n",
    "                data_dict[test_name] = df\n",
    "            else:\n",
    "                data_dict[test_name] = pd.concat([data_dict[test_name], df])\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "data_dict = create_merged_df(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personal health data plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating personal dataframe\n",
    "def create_personal_dataframe():\n",
    "    p_df = data_dict[\"personal\"].copy()\n",
    "    p_df.drop(0, inplace=True)\n",
    "    p_df.rename(columns={\n",
    "        0: \"session\",\n",
    "        1: \"time\",\n",
    "        2: \"heartrate\",\n",
    "        3: \"calories\",\n",
    "        4:\"temperature\",\n",
    "        5:\"body weight\",\n",
    "        6: \"muscle%\",\n",
    "        7: \"fat%\",\n",
    "    }, inplace=True)\n",
    "    p_df = p_df[[\n",
    "        \"participant\",\n",
    "        \"type\",\n",
    "        \"session\",\n",
    "        \"time\",\n",
    "        \"heartrate\",\n",
    "        \"calories\",\n",
    "        \"temperature\",\n",
    "        \"body weight\",\n",
    "        \"muscle%\",\n",
    "        \"fat%\"\n",
    "    ]]\n",
    "    \n",
    "    # fill missing and not correct values with the correct one.\n",
    "    p_df[\"heartrate\"] = pd.to_numeric(p_df[\"heartrate\"],errors='coerce')\n",
    "    p_df[\"heartrate\"] = p_df[\"heartrate\"].fillna(85)\n",
    "    p_df['session'] = p_df['session'].fillna(2)\n",
    "    p_df[\"calories\"] = p_df[\"calories\"].fillna(1118)\n",
    "    p_df[\"temperature\"] = p_df[\"temperature\"].fillna(36.4)\n",
    "    \n",
    "    p_df = p_df.astype({'heartrate': 'float', 'calories': 'float', 'temperature': 'float',\n",
    "                       'body weight': 'float', 'fat%': 'float', 'muscle%': 'float'})\n",
    "\n",
    "    return p_df\n",
    "\n",
    "personal_df = create_personal_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for plots to make them uniform\n",
    "participants = ['red', 'orange', 'green', 'blue', 'pink']\n",
    "colors      = ['salmon', 'skyblue']\n",
    "line_color  = 'black'\n",
    "plot_width  = 600\n",
    "plot_height = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_personal_plot(participant='pink', target = 'calories'):\n",
    "    '''\n",
    "    This function plots line_plots based on each participants and their health data\n",
    "    \n",
    "    Parameters: participant: 'green','pink', 'orange','blue','red'\n",
    "                target: \"heartrate\", \"calories\", \"temperature\"\n",
    "    \n",
    "    Return: line plot \n",
    "    Authors: Roya\n",
    "             Mahdiye\n",
    "    '''\n",
    "    target_units = {'heartrate': 'bpm', 'calories': 'kcals', 'temperature': '°C'}\n",
    "\n",
    "    personal_df = create_personal_dataframe()\n",
    "    personal_df = personal_df[personal_df[\"participant\"] == participant]\n",
    "\n",
    "    p = figure(x_range = [personal_df['time'].min(),personal_df['time'].max()*1.02], \n",
    "               y_range = [personal_df[target].min()*.5,personal_df[target].max()*1.3],\n",
    "               width=600, height=400, title=f'linechart of {target} data of participant {participant}', \n",
    "               x_axis_label=\"time (minutes)\", y_axis_label=f'{target} ({target_units[target]})')\n",
    "\n",
    "    x = personal_df[\"time\"].unique().tolist()\n",
    "    y1 = personal_df[(personal_df[\"type\"] == \"dehydration\") & (personal_df[\"session\"] == 1)][target].tolist()\n",
    "    y2 = personal_df[(personal_df[\"type\"] == \"dehydration\") & (personal_df[\"session\"] == 2)][target].tolist()\n",
    "    y3 = personal_df[(personal_df[\"type\"] == \"control\") & (personal_df[\"session\"] == 1)][target].tolist()\n",
    "    y4 = personal_df[(personal_df[\"type\"] == \"control\") & (personal_df[\"session\"] == 2)][target].tolist()\n",
    "    \n",
    "    # fitbit calories burned is an additive value of the whole day\n",
    "    # setting the calories values to start at 0 \n",
    "    if target == 'calories':\n",
    "        y1 = np.array(y1) - np.min(y1)\n",
    "        y2 = np.array(y2) - np.min(y2)\n",
    "        y3 = np.array(y3) - np.min(y3)\n",
    "        y4 = np.array(y4) - np.min(y4)\n",
    "        # resetting the yrange\n",
    "        p.y_range = Range1d(0, max([*y1, *y2, *y3, *y4])*1.3)\n",
    "        \n",
    "    # add multiple renderers\n",
    "    p.line(x, y1, legend_label=\"dehydration1\", color=\"blue\", line_width=2)\n",
    "    p.line(x, y2, legend_label=\"dehydration2\", color=\"red\", line_width=2)\n",
    "    p.line(x, y3, legend_label=\"control1\", color=\"green\", line_width=2)\n",
    "    p.line(x, y4, legend_label=\"control2\", color=\"orange\", line_width=2)\n",
    "    p.legend.location = 'top_left'\n",
    "    return p\n",
    "\n",
    "# participants =['green','pink', 'orange','blue','red']\n",
    "targets = [\"heartrate\", \"calories\", \"temperature\"]\n",
    "personal_plot = pn.interact(show_personal_plot, participant=participants, target = targets)\n",
    "personal_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_bar_personal(target):\n",
    "    '''\n",
    "    This function plots a bar_plot based on the target.\n",
    "    \n",
    "    parameter: target: one of personal data like:\n",
    "    \"heartrate\", \"calories\", \"temperature\", \"body weight\", \"fat%\", \"muscle%\"\n",
    "    \n",
    "    return: bar_plot\n",
    "    Author: Mahdiye\n",
    "    '''\n",
    "    \n",
    "    personal_df = create_personal_dataframe()\n",
    "    df = personal_df\n",
    "\n",
    "    #create a list of different session types\n",
    "    types = list(df['type'].unique())\n",
    "    \n",
    "    dff = df.groupby(['participant','type']).mean().reset_index()\n",
    "    \n",
    "    # create a list of participants\n",
    "    participants = list(dff['participant'].unique())\n",
    "\n",
    "    #create two list of reaction time regarding session types\n",
    "    control_mean = list(dff[dff['type'] =='control'][target])\n",
    "    dehydration_mean = list(dff[dff['type'] =='dehydration'][target])\n",
    "\n",
    "    #create a dictionary of 3 keys and values and then convert into a dataframe\n",
    "    data = {'participants' : participants,\n",
    "            'control'   : control_mean,\n",
    "            'dehydration'   : dehydration_mean,\n",
    "            }\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    palette =  [\"skyblue\", \"salmon\"] #colors\n",
    "\n",
    "    # create a list like:\n",
    "    # [ (\"blue\", \"control\"), (\"Ablue\", \"dehydration\"), (\"red\", \"control\"), (\"red\", \"dehydration\"), ... ]\n",
    "    x = [ (participant, test) for participant in participants for test in types ]\n",
    "    counts = sum(zip(data['control'], data['dehydration']), ()) # like an hstack\n",
    "\n",
    "    source = ColumnDataSource(data=dict(x=x, counts=counts))\n",
    "    # plot\n",
    "    p = figure(x_range=FactorRange(*x), y_range=[0, data['dehydration'].max()*1.3], width=600, height=400, \n",
    "                title='Average of '+ target,\n",
    "                y_axis_label=\"Reaction time(milliseconds)\",\n",
    "                x_axis_label=\"participant, session type\")\n",
    "\n",
    "    p.vbar(x='x', top='counts', width=1, source=source, line_color=\"black\",\n",
    "           fill_color=factor_cmap('x', palette=palette, factors=types, start=1, end=2))\n",
    "\n",
    "    p.y_range.start = 0\n",
    "    p.x_range.range_padding = 0.1\n",
    "    p.xaxis.major_label_orientation = 1\n",
    "    p.xgrid.grid_line_color = None\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_personal_standard_error(target):\n",
    "    '''\n",
    "    This function calculates upper and lower of whisker for error limits.\n",
    "    \n",
    "    parameter: target: one of personal data like:\n",
    "    \"heartrate\", \"calories\", \"temperature\", \"body weight\", \"fat%\", \"muscle%\"\n",
    "    \n",
    "    return: a dataframe contains mean of target, upper and lower columns\n",
    "    \n",
    "    Author: Roya (The main author)\n",
    "            Mahdiye (I had to change some parts to be run for my codes) \n",
    "    '''\n",
    "    personal_df = create_personal_dataframe()\n",
    "    df = personal_df\n",
    "    df_mean = df.groupby(by=[\"participant\", \"type\"]).agg(mean=(target, \"mean\"))\n",
    "    df_se = df.groupby(by=[\"participant\", \"type\"]).agg(se=(target, \"sem\"))\n",
    "    upper = df_mean[\"mean\"] + 1.96 * df_se[\"se\"]\n",
    "    lower = df_mean[\"mean\"] - 1.96 * df_se[\"se\"]\n",
    "    data = pd.concat([upper.rename(\"upper\"), lower.rename(\"lower\")], axis=1)\n",
    "    return data\n",
    "\n",
    "def plot_standard_error(plot, data):\n",
    "    '''\n",
    "    This function plots Whiskers and add it to main bar plot\n",
    "    \n",
    "    Parameters: plot= the given bar plot\n",
    "    \n",
    "    Returns: plot with whiskers\n",
    "    \n",
    "    Autor: Roya\n",
    "    '''\n",
    "    x = list(data.index.values)\n",
    "    data_map = {\n",
    "        'x': x,\n",
    "        'upper': data[\"upper\"].tolist(),\n",
    "        'lower': data[\"lower\"].tolist()\n",
    "\n",
    "        }\n",
    "    source = ColumnDataSource(data=data_map)\n",
    "\n",
    "    w = Whisker(source=source, base=\"x\", upper=\"upper\", lower=\"lower\", \n",
    "                line_color='black', level=\"overlay\")\n",
    "    w.upper_head.line_color = 'black'\n",
    "    w.lower_head.line_color = 'black'\n",
    "    w.upper_head.size = w.lower_head.size = 20\n",
    "    plot.add_layout(w)\n",
    "    return plot\n",
    "\n",
    "def personal_plot_error_bar(target):\n",
    "    '''\n",
    "    This function plots bar_plots with errors on them.\n",
    "    \n",
    "    parameter: target: one of personal data like:\n",
    "    \"heartrate\", \"calories\", \"temperature\", \"body weight\", \"fat%\", \"muscle%\"\n",
    "    \n",
    "    return: the main bar plot with errors, related to the target\n",
    "    \n",
    "    Author: Roya (The main author)\n",
    "            Mahdiye (I had to change some parts to be run for my codes) \n",
    "    '''\n",
    "    data_se = calculate_personal_standard_error(target)\n",
    "    p = total_bar_personal(target)\n",
    "    p = plot_standard_error(p, data_se)\n",
    "    return p\n",
    "targets = [\"heartrate\", \"calories\", \"temperature\", \"body weight\", \"fat%\", \"muscle%\"]\n",
    "personal_error_plot = pn.interact(personal_plot_error_bar, target = targets)\n",
    "personal_error_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dehydration percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain personal data\n",
    "df_health = data_dict['personal']\n",
    "# Theres one missing value in the green session. Fill it with the correct value\n",
    "df_health[0] = df_health[0].fillna(2)\n",
    "\n",
    "def dehydration_percentage(df_health):\n",
    "    '''\n",
    "    Function to obtain the % of dehydration per participant per session.\n",
    "    \n",
    "    Arguments:\n",
    "    df_health: Dataframe with all the participants personal data. \n",
    "\n",
    "    Returns:\n",
    "    A dataframe with the body weights and % of dehydration achived by every\n",
    "    participant in every session.\n",
    "    \n",
    "    Author:\n",
    "    Karina Diaz\n",
    "    '''\n",
    "    # Keep only the body weight data and drop NaN\n",
    "    body_weight = df_health[['participant','type', 0, 5]].dropna()\n",
    "    # drop the rows with strings on them (the ones with index ==0 )\n",
    "    body_weight = body_weight[body_weight.index!=0]\n",
    "    body_weight.rename(columns={0:'session', 5:'body weight'}, inplace=True)\n",
    "    body_weight = body_weight.astype({'body weight':'float'})\n",
    "\n",
    "    # calculate percentage of dehydration\n",
    "    body_weight['dehydration %'] = (body_weight.groupby(\n",
    "                                    ['participant','type','session']\n",
    "                                    )['body weight'].pct_change()) * 100\n",
    "    return body_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runing the function from above # Mahdiye\n",
    "dehydration_percentage = round(dehydration_percentage(df_health).dropna(),2)\n",
    "dehydration_percentage.drop(dehydration_percentage.columns[3], axis=1, inplace=True)\n",
    "dehydration_percentage = dehydration_percentage[dehydration_percentage['type']=='dehydration']\n",
    "dehydration_percentage = dehydration_percentage.T\n",
    "dehydration_percentage.columns = dehydration_percentage.iloc[0] # consider the first row as header\n",
    "dehydration_percentage = dehydration_percentage[1:]\n",
    "dehydration_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flanker Test Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Flanker dataframe\n",
    "def create_flanker_dataframe():\n",
    "    \"\"\"\n",
    "    cleaning data in order to be prepared for analysis step\n",
    "\n",
    "    Returns:\n",
    "        flanker_df(Dataframe) : Data of flanker test which is ready for proceesing.\n",
    "              \n",
    "    Author(s):\n",
    "        Roya Gharehbeiklou\n",
    "    \"\"\"\n",
    "    flanker_df = data_dict[\"flanker\"].copy()\n",
    "    #accroding to the concept of test, name of columns are changed \n",
    "    flanker_df.rename(columns={0: \"pattern\", 1: \"expression\", 2: \"correctness\", 3: \"response-time\"}, inplace=True)\n",
    "    #unused information for this test which was created in data integration step.\n",
    "    flanker_df.drop(columns=[4, 5, 6, 7, 8], inplace=True)\n",
    "    #Replacing contents of correctness column\n",
    "    flanker_df[\"correctness\"] = flanker_df[\"correctness\"].replace(1, \"correct\")\n",
    "    flanker_df[\"correctness\"] = flanker_df[\"correctness\"].replace(2, \"incorrect\")\n",
    "    flanker_df[\"correctness\"] = flanker_df[\"correctness\"].replace(3, \"not-answer\")\n",
    "    flanker_df[\"correctness\"] = flanker_df[\"correctness\"].fillna(\"not-answer\")\n",
    "    #Because of NaN values that may happend in raw data\n",
    "    flanker_df['response-time'].fillna((flanker_df['response-time'].mean()), inplace=True)\n",
    "    flanker_df['expression'].fillna(0, inplace=True)\n",
    "    return flanker_df\n",
    "\n",
    "flanker_df = create_flanker_dataframe()\n",
    "# summery of data for one user with correct answer type\n",
    "flanker_df[(flanker_df['correctness'] == 'correct') & (flanker_df['participant'] == 'red')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flanker_calculate_counts(flanker_df, answer_type=\"correct\"):\n",
    "    \"\"\"\n",
    "    Counts the number of answeres for each participants per session\n",
    "     \n",
    "    Arguments:\n",
    "        flanker_df(Dataframe): Dataframe with all the participants flanker test data. \n",
    "        answer_type(object): 'correct', 'incorrect','not-answer'\n",
    "        \n",
    "    Returns:\n",
    "        data(Dataframe) : Average number of answers for each participant in\n",
    "                          dehydaration and control.\n",
    "              \n",
    "    Author(s):\n",
    "        Roya Gharehbeiklou\n",
    "    \"\"\"\n",
    "    flanker_df = flanker_df[flanker_df[\"correctness\"] == answer_type]\n",
    "    flanker_df = flanker_df.groupby([\"participant\", \"type\", \"repeat\"])[\"correctness\"].count().reset_index()\n",
    "    data = flanker_df.groupby(by=[\"participant\", \"type\"])[\"correctness\"].mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "def calculate_percentage(flanker_df, answer_type=\"correct\"):\n",
    "    \"\"\"\n",
    "    The number of answeres(percentagewise) for each participants per session\n",
    "     \n",
    "    Arguments:\n",
    "        flanker_df(Dataframe): Dataframe with all the participants flanker test data. \n",
    "        answer_type(object): 'correct', 'incorrect','not-answer'\n",
    "        \n",
    "    Returns:\n",
    "        data(Dataframe) : Average number of answers for each participant in\n",
    "                          dehydaration and control.\n",
    "              \n",
    "    Author(s):\n",
    "        Roya Gharehbeiklou\n",
    "    \"\"\"\n",
    "    # calculate all number of questions per session\n",
    "    df_all = flanker_df.groupby([\"participant\", \"type\", \"repeat\"]).agg(count=(\"correctness\", \"count\"))\n",
    "    # calculate the number of answer type chosen\n",
    "    flanker_df = flanker_df[flanker_df[\"correctness\"] == answer_type]\n",
    "    df_correct = flanker_df.groupby([\"participant\", \"type\", \"repeat\"]).agg(count=(\"correctness\", \"count\"))\n",
    "\n",
    "    # Average calculation\n",
    "    flanker_df = round(df_correct[\"count\"] * 100 / df_all[\"count\"], 2).rename(\"percentage\").reset_index().fillna(0)\n",
    "    data = flanker_df.groupby(by=[\"participant\", \"type\"])[\"percentage\"].mean()\n",
    "    return data\n",
    "\n",
    "def flanker_calculate_responce_time(flanker_df):\n",
    "    \"\"\"\n",
    "    Counts the number of answeres for each participants per session\n",
    "     \n",
    "    Arguments:\n",
    "        flanker_df(Dataframe): Dataframe with all the participants flanker test data. \n",
    "        \n",
    "    Returns:\n",
    "        data(Dataframe) : Average number of answers for each participant in\n",
    "                          dehydaration and control.\n",
    "              \n",
    "    Author(s):\n",
    "        Roya Gharehbeiklou\n",
    "    \"\"\"\n",
    "    data = flanker_df.groupby(by=[\"participant\", \"type\"])[\"response-time\"].mean()\n",
    "\n",
    "    return data\n",
    "def calculate_flanker_standard_error(flanker_df, answer_type, column_name=\"correctness\"):\n",
    "    \"\"\"\n",
    "    This function calculate SE for each participants per session\n",
    "     \n",
    "    Arguments:\n",
    "        flanker_df(Dataframe): Dataframe with all the participants flanker test data. \n",
    "        answer_type(str): 'correct', 'incorrect','not-answer'\n",
    "        column_name(str): which can be any column but we use it for \"response-time\" and \"correctness\"\n",
    "    Returns:\n",
    "        data(Dataframe) : upper an lower of Error for each participants per session\n",
    "              \n",
    "    Author(s):\n",
    "        Roya Gharehbeiklou\n",
    "    \"\"\"\n",
    "    if column_name == \"correctness\":\n",
    "        flanker_df = flanker_df[flanker_df[\"correctness\"] == answer_type]\n",
    "        flanker_df = flanker_df.groupby([\"participant\", \"type\", \"repeat\"])[\"correctness\"].count().reset_index()\n",
    "        df_mean = flanker_df.groupby(by=[\"participant\", \"type\"]).agg(mean=(\"correctness\", \"mean\"))\n",
    "        df_se = flanker_df.groupby(by=[\"participant\", \"type\"]).agg(se=(\"correctness\", \"sem\"))\n",
    "\n",
    "    elif column_name == \"response-time\":\n",
    "        df_mean = flanker_df.groupby(by=[\"participant\", \"type\"]).agg(mean=(\"response-time\", \"mean\"))\n",
    "        df_se = flanker_df.groupby(by=[\"participant\", \"type\"]).agg(se=(\"response-time\", \"sem\"))\n",
    "        \n",
    "    upper = df_mean[\"mean\"] + 1.96 * df_se[\"se\"]\n",
    "    lower = df_mean[\"mean\"] - 1.96 * df_se[\"se\"]\n",
    "    data = pd.concat([upper.rename(\"upper\"), lower.rename(\"lower\")], axis=1)\n",
    "    return data\n",
    "\n",
    "flanker_df = create_flanker_dataframe()\n",
    "data_count = flanker_calculate_responce_time(flanker_df)\n",
    "print(data_count)\n",
    "data = calculate_flanker_standard_error(flanker_df, 'correct', \"response-time\")\n",
    "print(data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of type answer = not-answer was considered as outlier. \n",
    "\n",
    "```\n",
    "result:\n",
    "participant  type       \n",
    "orange       control        2.0\n",
    "             dehydration    1.0\n",
    "Name: correctness, dtype: float64\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flanker Test plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(data, title, max_y=100, x_label=\"\", y_label=\"\", palette=colors, factors=[\"dehydration\", \"control\"]):\n",
    "    \"\"\"\n",
    "    This function is defined to be used by other plots that need Bokeh library\n",
    "\n",
    "    Args:\n",
    "        data (Dataframe): datafarme used to plot\n",
    "        title (Str): description of plot\n",
    "        x_label (str, optional): description of x axis\n",
    "        y_label (str, optional): description of y axis\n",
    "        palette (Dict): colors used in plot\n",
    "        factors (list): description of categories, Defaults to [\"dehydration\", \"control\"].\n",
    "\n",
    "    Returns:\n",
    "        p: plot\n",
    "    \n",
    "    Author(s):\n",
    "        Roya Gharehbeiklou\n",
    "    \"\"\"\n",
    "    index_cmap = factor_cmap('x', palette=palette, factors=factors, start=1, end=2)\n",
    "    x = list(data.index.values)\n",
    "    data_map = {\n",
    "        'x': x,\n",
    "        'counts': data.tolist()\n",
    "        }\n",
    "\n",
    "    source = ColumnDataSource(data=data_map)\n",
    "    p = figure(x_range=FactorRange(*x), y_range=(0, max_y), width=plot_width, height=plot_height, title=title, x_axis_label=x_label, y_axis_label=y_label)\n",
    "\n",
    "    p.vbar(x='x', top='counts', source=source, fill_color=index_cmap, line_color=line_color)\n",
    "\n",
    "    p.y_range.start = 0\n",
    "    p.x_range.range_padding = 0.1\n",
    "    p.xaxis.major_label_orientation = 1\n",
    "    p.xgrid.grid_line_color = None\n",
    "    return p\n",
    "\n",
    "def plot_standard_error(plot, data):\n",
    "    \"\"\"\n",
    "    This function is used to show error plot\n",
    "\n",
    "    Args:\n",
    "        plot (plot): plot\n",
    "        data (dataframe): data which is intended to be drawn\n",
    "\n",
    "    Returns:\n",
    "        plot: plot\n",
    "    \n",
    "    Author(s):\n",
    "        Roya Gharehbeiklou\n",
    "    \"\"\"\n",
    "    x = list(data.index.values)\n",
    "    data_map = {\n",
    "        'x': x,\n",
    "        'upper': data[\"upper\"].tolist(),\n",
    "        'lower': data[\"lower\"].tolist()\n",
    "\n",
    "        }\n",
    "    source = ColumnDataSource(data=data_map)\n",
    "\n",
    "    w = Whisker(source=source, base=\"x\", upper=\"upper\", lower=\"lower\", \n",
    "            line_color='black', level=\"overlay\")\n",
    "    w.upper_head.line_color = 'black'\n",
    "    w.lower_head.line_color = 'black'\n",
    "    w.upper_head.size = w.lower_head.size = 20\n",
    "    plot.add_layout(w)\n",
    "    return plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flanker_plot_count(answer_type=\"correct\"): \n",
    "    \"\"\"\n",
    "    This function shows the answer types for each participant per session\n",
    "\n",
    "    Args:\n",
    "        answer_type (str, optional): answer types of 'correct' or 'incorrect'. Defaults to \"correct\".\n",
    "\n",
    "    Returns:\n",
    "        p: plot\n",
    "    Author(s):\n",
    "        Roya Gharehbeiklou\n",
    "    \"\"\"\n",
    "    flanker_df = create_flanker_dataframe()\n",
    "    data = flanker_calculate_counts(flanker_df, answer_type)\n",
    "    return show_plot(data, f\"Flanker Test _ Average of {answer_type} answers\", 50, \"participant/session\", \"count\")\n",
    "\n",
    "answer_types =['correct','incorrect']\n",
    "flanker_count_plot = flanker_plot_count()\n",
    "flanker_counts = pn.interact(flanker_plot_count, answer_type = answer_types)\n",
    "flanker_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flanker_plot_percentage(answer_type=\"correct\"): \n",
    "    \"\"\"\n",
    "    This function shows the answer types(percentagwise) for each participant per session\n",
    "\n",
    "    Args:\n",
    "        answer_type (str, optional): answer types of 'correct' or 'incorrect'. Defaults to \"correct\".\n",
    "\n",
    "    Returns:\n",
    "        p: plot\n",
    "    Author(s):\n",
    "        Roya Gharehbeiklou\n",
    "    \"\"\"\n",
    "    flanker_df = create_flanker_dataframe()\n",
    "    data = calculate_percentage(flanker_df, answer_type)\n",
    "    return show_plot(data, f\"Flanker Test _ Percentage of {answer_type} answers\", 100, \"participant/session\", \"Percentage\")\n",
    "\n",
    "answer_types =['correct','incorrect']\n",
    "flanker_percentage = pn.interact(flanker_plot_percentage, answer_type = answer_types)\n",
    "flanker_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flanker_box_plot():\n",
    "    \"\"\"\n",
    "    This function is defined to draw the box plot using hvplot from pandas \n",
    "        that inheritances from Bokeh\n",
    "\n",
    "    Returns:\n",
    "        flanker_boxplot: hvplot\n",
    "    Author(s):\n",
    "        Roya Gharehbeiklou\n",
    "    \"\"\"\n",
    "    flanker_df = create_flanker_dataframe()\n",
    "    #dfi = flanker_df.interactive(loc='top').to_dataframe()\n",
    "    flanker_boxplot = flanker_df[flanker_df['correctness'] == 'correct'][\n",
    "        [\n",
    "            'response-time', \n",
    "            'participant', \n",
    "            'type'\n",
    "        ]].hvplot.box(\n",
    "            by='type', \n",
    "            groupby='participant',\n",
    "            title='Reaction time for correct responses',\n",
    "            xlabel='Session Type', \n",
    "            ylabel='Resopnse Time (ms)',height=400, width=400)\n",
    "    return flanker_boxplot\n",
    "    \n",
    "        \n",
    "flanker_boxplot = flanker_box_plot()\n",
    "flanker_boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flanker_plot_error(answer_type=\"correct\", participants=participants): \n",
    "    \"\"\"\n",
    "    This function is used to plot errors over counts of correctness column\n",
    "\n",
    "    Args:\n",
    "        answer_type (str, optional): correct and incorrect. Defaults to \"correct\".\n",
    "        Participants (list[str] , optional): per participant\n",
    "\n",
    "    Returns:\n",
    "        p: plot\n",
    "    Author(s):\n",
    "        Roya Gharehbeiklou\n",
    "    \"\"\"\n",
    "    flanker_df = create_flanker_dataframe()\n",
    "    flanker_df = flanker_df[flanker_df.participant.isin(participants)]\n",
    "    data = flanker_calculate_counts(flanker_df, answer_type)\n",
    "    data_se = calculate_flanker_standard_error(flanker_df, answer_type, \"correctness\")\n",
    "    p = show_plot(data, f\"Flanker Test _ {answer_type} answers\", 70, \"participant/session\", \"Counts\" )\n",
    "    p = plot_standard_error(p, data_se)\n",
    "    return p\n",
    "\n",
    "\n",
    "answer_types =['correct','incorrect']\n",
    "inter_plot = pn.interact(flanker_plot_error, answer_type = ['correct','incorrect'])\n",
    "inter_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flanker_plot_error_response_time(participants=participants): \n",
    "    \"\"\"\n",
    "    This function is used to plot errors over responce time\n",
    "\n",
    "    Args:\n",
    "        Participants (list[str] , optional): per participant\n",
    "\n",
    "    Returns:\n",
    "        p: plot\n",
    "    Author(s):\n",
    "        Roya Gharehbeiklou\n",
    "    \"\"\"\n",
    "    flanker_df = create_flanker_dataframe()\n",
    "    flanker_df = flanker_df[flanker_df.participant.isin(participants)]\n",
    "    data = flanker_calculate_responce_time(flanker_df)\n",
    "    data_se = calculate_flanker_standard_error(flanker_df, answer_type=\"\", column_name=\"response-time\")\n",
    "    p = show_plot(data, f\"Flanker Test - response time\", 1000, \"participant/session\", \"time(ms)\" )\n",
    "    p = plot_standard_error(p, data_se)\n",
    "    return p\n",
    "\n",
    "\n",
    "# show(flanker_barplot)\n",
    "inter_plot = flanker_plot_error_response_time()\n",
    "show(inter_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stroop Test  Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stroop_test(): # Mahdiye\n",
    "    '''\n",
    "    This function creates a tiny dataframe from stroop test data.\n",
    "    \n",
    "    Parameter:\n",
    "    \n",
    "    Return: Stroop test dataframe\n",
    "    \n",
    "    Author: Mahdiye\n",
    "    '''\n",
    "    total_dict = create_merged_df(config)\n",
    "    stroop_df = total_dict['stroop']\n",
    "    stroop_df.drop(stroop_df.columns[[3,7]], axis=1, inplace=True)\n",
    "    stroop_df = stroop_df.set_axis(['participant', 'type','repeat','word name','word color',\n",
    "                                    'name_color match','pressed _key','status','reaction_time'], axis=1)\n",
    "    return stroop_df\n",
    "\n",
    "stroop_df = stroop_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_stroop_bar_plot(participant='blue'):\n",
    "    '''\n",
    "    This function plots a bar_plot per participant.\n",
    "    \n",
    "    Parameter: participant: 'blue','red','orange','green','pink'\n",
    "    \n",
    "    Return: bar plot\n",
    "    \n",
    "    Author: Mahdiye\n",
    "    '''\n",
    "    stroop_df = stroop_test()\n",
    "    df = stroop_df[stroop_df['participant']==participant]\n",
    "    \n",
    "    dff= df.groupby('type').min().reset_index()\n",
    "    p = figure(x_range=dff['type'], height=350, \n",
    "               title=f'Stroop Test {participant}', y_axis_label=\"Reaction time(milliseconds)\")\n",
    "    p.vbar(x=dff['type'], bottom=0,top=dff['reaction_time'], width=0.5, line_color='black', color=participant)\n",
    "    return p\n",
    "\n",
    "#interactive plots\n",
    "participants_color =['blue','red','orange','green','pink']\n",
    "inter_plot = pn.interact(individual_stroop_bar_plot, participant = participants_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_stroop_box_plot(participant):\n",
    "    '''\n",
    "    This function plots a box_plot per participant.\n",
    "    \n",
    "    Parameter: participant: 'blue','red','orange','green','pink'\n",
    "    \n",
    "    Return: bar plot\n",
    "    \n",
    "    Author: Mahdiye\n",
    "    '''\n",
    "    \n",
    "    stroop_df = stroop_test()\n",
    "    df = stroop_df[stroop_df['participant']==participant]\n",
    "    kinds = df['type'].unique()\n",
    "    \n",
    "    # compute quantiles\n",
    "    qs = df.groupby('type').reaction_time.quantile([0.25, 0.5, 0.75])\n",
    "    qs = qs.unstack().reset_index()\n",
    "    qs.columns = ['type', \"q1\", \"q2\", \"q3\"]\n",
    "    df = pd.merge(df, qs, on='type', how=\"left\")\n",
    "\n",
    "    # compute IQR outlier bounds\n",
    "    iqr = df.q3 - df.q1\n",
    "    df[\"upper\"] = df.q3 + 1.5*iqr\n",
    "    df[\"lower\"] = df.q1 - 1.5*iqr\n",
    "\n",
    "    source = ColumnDataSource(df)\n",
    "\n",
    "    p = figure(x_range=kinds,y_range=[-100,stroop_df['reaction_time'].max() * 1.3],\n",
    "                title=\"box plot of stroop test \"+participant,\n",
    "               background_fill_color=\"#eaefef\", y_axis_label=\"Reaction time(milliseconds)\")\n",
    "\n",
    "\n",
    "    # outlier range\n",
    "    whisker = Whisker(base='type', upper=\"upper\", lower=\"lower\", source=source)\n",
    "    whisker.upper_head.size = whisker.lower_head.size = 20\n",
    "    p.add_layout(whisker)\n",
    "\n",
    "    # quantile boxes\n",
    "    p.vbar('type', 0.5, \"q2\", \"q3\", color = participant,bottom=0, source=source, line_color=\"black\")\n",
    "    p.vbar('type', 0.5, \"q1\", \"q2\", color=participant, bottom=0, source=source, line_color=\"black\")\n",
    "    \n",
    "    # outliers\n",
    "    outliers = df[~df.reaction_time.between(df.lower, df.upper)]\n",
    "    p.scatter('type', 'reaction_time', source=outliers, size=6, color=\"black\", alpha=0.5)\n",
    "\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.major_label_text_font_size=\"14px\"\n",
    "    p.axis.axis_label_text_font_size=\"12px\"\n",
    "\n",
    "    return p\n",
    "    \n",
    "#interactive plots\n",
    "participants_color =['blue','red','orange','green','pink']\n",
    "stroop_boxplot = pn.interact(individual_stroop_box_plot, participant = participants_color)\n",
    "# stroop_boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stroop error bar for the number of correct answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_bar_stroop(participants):\n",
    "    '''\n",
    "    This function plots a bar_plot for all participants based on the number of correct answers.\n",
    "    \n",
    "    Parameter:\n",
    "    \n",
    "    Return: bar plot\n",
    "    \n",
    "    Author: Mahdiye\n",
    "    '''\n",
    "    \n",
    "    types = list(stroop_df['type'].unique())\n",
    " #     participants = list(stroop_df['participant'].unique())\n",
    "\n",
    "    df = stroop_df[stroop_df['status'] ==1]\n",
    "    df = df[df.participant.isin(participants)]\n",
    "    dff = df.groupby([\"participant\", \"type\", \"repeat\"])[\"status\"].count().reset_index()\n",
    "    dfff = dff.groupby([\"participant\", \"type\"])['status'].mean().reset_index()\n",
    "    participants = list(dfff['participant'].unique())\n",
    "    \n",
    "    de_list = dfff[dfff['type']=='dehydration'].status.to_list()\n",
    "    co_list = dfff[dfff['type']=='control'].status.to_list()\n",
    "    \n",
    "    data = {'participants' : participants,\n",
    "            'control'   : co_list,\n",
    "            'dehydration'   : de_list,\n",
    "            }\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    palette = [\"skyblue\", \"salmon\"] #colors\n",
    "    x = [ (participant, test) for participant in participants for test in types ]\n",
    "    counts = sum(zip(data['control'], data['dehydration']), ()) # like an hstack\n",
    "\n",
    "    source = ColumnDataSource(data=dict(x=x, counts=counts))\n",
    "    # plot\n",
    "    p = figure(x_range=FactorRange(*x), width=plot_width, height=plot_height, title='The number of correct answers of stroop test',\n",
    "               y_axis_label= ' correct answers count', x_axis_label=\"participant, session type\")\n",
    "\n",
    "    p.vbar(x='x', top='counts', width=1, source=source, line_color=line_color,\n",
    "           fill_color=factor_cmap('x', palette=palette, factors=types, start=1, end=2))\n",
    "\n",
    "    p.y_range.start = 0\n",
    "    p.x_range.range_padding = 0.1\n",
    "    p.xaxis.major_label_orientation = 1\n",
    "    p.xgrid.grid_line_color = None\n",
    "    return p\n",
    "\n",
    "# show(status_bar_stroop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroop_df = stroop_test()\n",
    "def calculate_status_standard_error(stroop_df):\n",
    "    '''\n",
    "    This function calculates upper and lower of whisker for error limits.\n",
    "    \n",
    "    parameter: target: one of personal data like:\n",
    "    \"heartrate\", \"calories\", \"temperature\", \"body weight\", \"fat%\", \"muscle%\"\n",
    "    \n",
    "    return: a dataframe contains mean of target, upper and lower columns\n",
    "    \n",
    "    Author: Roya (The main author)\n",
    "            Mahdiye (I had to change some parts to be run for my codes) \n",
    "    '''\n",
    "   \n",
    "    df = stroop_df[stroop_df['status'] ==1]\n",
    "    df = df.groupby([\"participant\", \"type\", \"repeat\"])[\"status\"].count().reset_index()    \n",
    "    df_mean = df.groupby(by=[\"participant\", \"type\"]).agg(mean=(\"status\", \"mean\"))\n",
    "    df_se = df.groupby(by=[\"participant\", \"type\"]).agg(se=(\"status\", \"sem\"))\n",
    "#     print(df_se)\n",
    "    upper = df_mean[\"mean\"] + 1.96 * df_se[\"se\"]\n",
    "    lower = df_mean[\"mean\"] - 1.96 * df_se[\"se\"]\n",
    "    data = pd.concat([upper.rename(\"upper\"), lower.rename(\"lower\")], axis=1)\n",
    "    return data\n",
    "\n",
    "def stroop_status_plot_error(participants):\n",
    "    '''\n",
    "    This function plots bar_plots with errors on them.\n",
    "    \n",
    "    parameter: target: one of personal data like:\n",
    "    \"heartrate\", \"calories\", \"temperature\", \"body weight\", \"fat%\", \"muscle%\"\n",
    "    \n",
    "    return: the main bar plot with errors, related to the target\n",
    "    \n",
    "    Author: Roya (The main author)\n",
    "            Mahdiye (I had to change some parts to be run for my codes) \n",
    "    '''\n",
    "    stroop_df = stroop_test()\n",
    "    stroop_df = stroop_df[stroop_df.participant.isin(participants)]  # select participants\n",
    "    data_se = calculate_status_standard_error(stroop_df)\n",
    "#     print(data_se)\n",
    "    p = status_bar_stroop(participants)\n",
    "    p = plot_standard_error(p, data_se)\n",
    "    return p\n",
    "\n",
    "show(stroop_status_plot_error(participants))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stroop error bar for reaction time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_bar_stroop(participants):\n",
    "    '''\n",
    "    This function plots a bar_plot for all participants based on the average of reaction time.\n",
    "    \n",
    "    Parameter:\n",
    "    \n",
    "    Return: bar plot\n",
    "    \n",
    "    Author: Mahdiye\n",
    "    '''\n",
    "    \n",
    "    stroop_df = stroop_test()\n",
    "    df = stroop_df[stroop_df.participant.isin(participants)]  # select participants\n",
    "\n",
    "    #create a list of different session types\n",
    "    types = list(df['type'].unique())\n",
    "    \n",
    "    dff = df.groupby(['participant','type']).mean().reset_index()\n",
    "    \n",
    "    # create a list of participants\n",
    "    participants = list(dff['participant'].unique())\n",
    "\n",
    "    #create two list of reaction time regarding session types\n",
    "    control_mean = list(dff[dff['type'] =='control'].reaction_time)\n",
    "    dehydration_mean = list(dff[dff['type'] =='dehydration'].reaction_time)\n",
    "\n",
    "    #create a dictionary of 3 keys and values and then convert into a dataframe\n",
    "    data = {'participants' : participants,\n",
    "            'control'   : control_mean,\n",
    "            'dehydration'   : dehydration_mean,\n",
    "            }\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    palette =  [\"skyblue\", \"salmon\"] #colors\n",
    "\n",
    "    # create a list like:\n",
    "    # [ (\"blue\", \"control\"), (\"Ablue\", \"dehydration\"), (\"red\", \"control\"), (\"red\", \"dehydration\"), ... ]\n",
    "    x = [ (participant, test) for participant in participants for test in types ]\n",
    "    counts = sum(zip(data['control'], data['dehydration']), ()) # like an hstack\n",
    "\n",
    "    source = ColumnDataSource(data=dict(x=x, counts=counts))\n",
    "    # plot\n",
    "    p = figure(x_range=FactorRange(*x), y_range=[0, data['dehydration'].max()+200], width=600, height=400, \n",
    "                title='Average of reaction time stroop test',\n",
    "                y_axis_label=\"Reaction time(milliseconds)\",\n",
    "                x_axis_label=\"participant, session type\")\n",
    "\n",
    "    p.vbar(x='x', top='counts', width=1, source=source, line_color=\"black\",\n",
    "           fill_color=factor_cmap('x', palette=palette, factors=types, start=1, end=2))\n",
    "\n",
    "    p.y_range.start = 0\n",
    "    p.x_range.range_padding = 0.1\n",
    "    p.xaxis.major_label_orientation = 1\n",
    "    p.xgrid.grid_line_color = None\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stroop_standard_error(stroop_df, participants):\n",
    "    '''\n",
    "    This function calculates upper and lower of whisker for error limits.\n",
    "    \n",
    "    parameter: target: one of personal data like:\n",
    "    \"heartrate\", \"calories\", \"temperature\", \"body weight\", \"fat%\", \"muscle%\"\n",
    "    \n",
    "    return: a dataframe contains mean of target, upper and lower columns\n",
    "    \n",
    "    Author: Roya (The main author)\n",
    "            Mahdiye (I had to change some parts to be run for my codes) \n",
    "    '''\n",
    "    stroop_df = stroop_df[stroop_df.participant.isin(participants)]\n",
    "    df_mean = stroop_df.groupby(by=[\"participant\", \"type\"]).agg(mean=(\"reaction_time\", \"mean\"))\n",
    "    df_se = stroop_df.groupby(by=[\"participant\", \"type\"]).agg(se=(\"reaction_time\", \"sem\"))\n",
    "    upper = df_mean[\"mean\"] + 1.96 * df_se[\"se\"]\n",
    "    lower = df_mean[\"mean\"] - 1.96 * df_se[\"se\"]\n",
    "    data = pd.concat([upper.rename(\"upper\"), lower.rename(\"lower\")], axis=1)\n",
    "    return data\n",
    "\n",
    "def stroop_plot_error_bar(participants):\n",
    "    '''\n",
    "    This function plots bar_plots with errors on them.\n",
    "    \n",
    "    parameter: target: one of personal data like:\n",
    "    \"heartrate\", \"calories\", \"temperature\", \"body weight\", \"fat%\", \"muscle%\"\n",
    "    \n",
    "    return: the main bar plot with errors, related to the target\n",
    "    \n",
    "    Author: Roya (The main author)\n",
    "            Mahdiye (I had to change some parts to be run for my codes) \n",
    "    '''    \n",
    "    data_se = calculate_stroop_standard_error(stroop_df, participants)\n",
    "    p = total_bar_stroop(participants)\n",
    "    p = plot_standard_error(p, data_se)\n",
    "    return p\n",
    "\n",
    "stroop_rt_barplot = stroop_plot_error_bar(participants)\n",
    "show(stroop_rt_barplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Signal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_meanings = {'Column':[0,1,2,3,4,5,6,7],\n",
    "                   'Meaning':['trial type (go or nogo)', \n",
    "                              'required response (left or right)', \n",
    "                              'when the stop signal is shown (or 0 if not)', \n",
    "                              'response time 1', \n",
    "                              'status 1 (1=correct, 2=wrong, 3=timeout)',\n",
    "                              'response time 2 (only in no go trials)',\n",
    "                              'status 2 (only in no go trials; 1=correct, 2=wrong, 3=timeout)',\n",
    "                              '1=trial is correct ; 0=trial is not correct']} \n",
    "\n",
    "column_meanings = pd.DataFrame(column_meanings)\n",
    "column_meanings.set_index('Column', inplace=True)\n",
    "column_meanings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_test(stop_df): # Jacob\n",
    "    \n",
    "    # renaming and reordering columns\n",
    "    stop_df.rename(columns = {0:'trial_type', 1:'correct_resp.', \n",
    "                            2:'stop_signal_delay', 3:'response_time',\n",
    "                            4:'status', 5:'resonse_time_nogo',\n",
    "                            6:'status_nogo', 7:'correct'}, inplace = True)\n",
    "\n",
    "    stop_df = stop_df[['participant', 'type', 'repeat', 'trial_type',\n",
    "                    'correct_resp.', 'correct', 'response_time',\n",
    "                    'status', 'stop_signal_delay', 'resonse_time_nogo',\n",
    "                    'status_nogo']]\n",
    "\n",
    "    # The average resonse time for go trials per trial type\n",
    "    avg_go_resp_time = stop_df[stop_df['trial_type'] == 'go'].groupby([\n",
    "        'participant', 'type','status']).mean()['response_time']\n",
    "\n",
    "\n",
    "    # The average resonse time for no-go trials per correct/incorrect trial\n",
    "    avg_nogo_resp_time = stop_df[stop_df['trial_type'] == 'nogo'].groupby([\n",
    "        'participant', 'type','status_nogo']).mean()['response_time']\n",
    "\n",
    "    # Good to keep in mind that here, status three corresponds with a correct trail\n",
    "    # Since there was no press in a no-go trial.\n",
    "\n",
    "    # Number of errors and time-outs in go trials\n",
    "    errors_timeout_go = stop_df[(stop_df['trial_type'] == 'go') & \n",
    "                                (stop_df['status'] != 1.0)].groupby([\n",
    "                                    'participant', 'type', 'repeat','status']).count()['trial_type']\n",
    "\n",
    "    # Number of errors and time-outs in no-go trials\n",
    "    errors_timeout_nogo = stop_df[stop_df['trial_type'] == 'nogo'].groupby([\n",
    "        'participant', 'type', 'repeat','status_nogo']).count()['trial_type']\n",
    "    \n",
    "    stop_signal_boxplot = stop_df[(stop_df['trial_type'] == 'go') & (\n",
    "                                   stop_df['correct'] == 1)][\n",
    "                                       ['response_time', 'participant', 'type']\n",
    "                                       ].hvplot.box(by=['participant', 'type'], \n",
    "                                                    #groupby='participant',\n",
    "                                                    title='Reaction time for correct responses',\n",
    "                                                    xlabel='Session Type',\n",
    "                                                    ylabel='Resopnse Time (ms)',\n",
    "                                                    rot=40)\n",
    "                                    \n",
    "    \n",
    "    return (avg_go_resp_time, avg_nogo_resp_time, \n",
    "            errors_timeout_go, errors_timeout_nogo,\n",
    "            stop_signal_boxplot, stop_df)\n",
    "\n",
    "# callig the function\n",
    "(avg_go_resp_time, avg_nogo_resp_time,\n",
    " errors_timeout_go, errors_timeout_nogo,\n",
    " stop_signal_boxplot, stop_df) = stop_test(data_dict['stop'])\n",
    "\n",
    "#and the error bart\n",
    "avg_go_resp_bar = pf.plot_error_bar(stop_df, 'response_time',\n",
    "                                    participants=participants,\n",
    "                                    title='Stop Signal Task - Average response time in go trials per participant, per session type', \n",
    "                                    xlabel='Participant, Session type',\n",
    "                                    ylabel='Average response time (ms)')\n",
    "\n",
    "show(avg_go_resp_bar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_signal_boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbal Fluency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def verbal_test(verbal_df): # Jacob\n",
    "    \"\"\"\n",
    "    This function takes the verbal dataframe from the data_dict, turns it into\n",
    "    its own df, calculates average words produced per participant and plots this\n",
    "    \n",
    "    Parameters\n",
    "        verbal_df: The data_dict with verbal as key\n",
    "        \n",
    "    Returns\n",
    "        verbal_df: The verbal task DataFrame\n",
    "        verbal_avg: A dataframe with the average words produced per participant\n",
    "                    and session type\n",
    "        verbal_barplot: A barplot displaying the verbal_avg data.\n",
    "    \"\"\"\n",
    "    \n",
    "    verbal_df = data_dict['verbal'].copy()\n",
    "    verbal_df = verbal_df[verbal_df[1] != 'word count'] # to remove silly headers\n",
    "    verbal_df.rename(columns={0:'word_type', 1:'n'}, inplace=True)\n",
    "    verbal_df['n'] = verbal_df['n'].astype(int)\n",
    "\n",
    "    verbal_avg = verbal_df.groupby(['participant', 'type']).mean().round(2)\n",
    "    \n",
    "    verbal_avg = verbal_df.groupby(['participant', 'type']).mean().round(2)\n",
    "    \n",
    "    return verbal_df, verbal_avg\n",
    "\n",
    "# Calling the function\n",
    "verbal_df, verbal_avg = verbal_test(data_dict['verbal'])\n",
    "\n",
    "# Creating a barplot\n",
    "verbal_barplot = pf.plot_error_bar(verbal_df, 'n',\n",
    "                                   participants=participants,\n",
    "                                   title='Verbal Fluency Task - Number of words produced per participant, per session type',\n",
    "                                   xlabel='Participant, Session type',\n",
    "                                   ylabel='Average words produced')\n",
    "\n",
    "# Now showing it.\n",
    "show(verbal_barplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit Span Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_test(digit_df):\n",
    "    '''\n",
    "    Function to analyse the Digit Span preprocessed data. Calculates the mean \n",
    "    and the standar errors needed to plot, makes some calculation per columns to\n",
    "    better understard the results. \n",
    "    \n",
    "    Arguments:\n",
    "    digit_df: Merged dataframe with the digit span results preprocessed from every\n",
    "    patient. It is obtained from the dictionary created in the 'create_merged_df' \n",
    "    function and the key \"digit\".   \n",
    "\n",
    "    Returns:\n",
    "    A dataframe with the mean and standar error for 3 different analyses \n",
    "    (sequence lenght, number of errors made and clicks difference).\n",
    "    \n",
    "    Author:\n",
    "    Karina Diaz\n",
    "    '''\n",
    "    # Change data types\n",
    "    digit_df = digit_df.astype({'participant': 'string',\n",
    "                                'type': 'string',\n",
    "                                'repeat': 'int',\n",
    "                                'seq length':'float',\n",
    "                                'errors': 'float',\n",
    "                                'clicks expected': 'float',\n",
    "                                'clicks observed': 'float'})\n",
    "\n",
    "    digit_df['clicks difference'] = digit_df['clicks observed'] - digit_df['clicks expected']\n",
    "\n",
    "    # Make calculations by column taking the groups into account               \n",
    "    digit_grouped = digit_df.groupby(['participant','type', 'repeat']).agg(\n",
    "                                                    {'seq length': 'max',\n",
    "                                                    'errors': 'mean', \n",
    "                                                    'clicks difference':'mean'})\n",
    "\n",
    "    # Deleate -1 to the longest sequence because that does not count for the analysis\n",
    "    digit_grouped['seq length'] = digit_grouped['seq length'] - 1\n",
    "\n",
    "    # Obtain mean and estandar error\n",
    "    digit_mean_sem = digit_grouped.groupby(['participant', 'type']).agg(['mean','sem'])\n",
    "\n",
    "    return digit_mean_sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running digit_test function\n",
    "digit_mean_sem = digit_test(digit_df = data_dict[\"digit\"])\n",
    "\n",
    "def digit_barplots(analysis, participants):\n",
    "    '''Function to plot the digit span data with error bars.\n",
    "\n",
    "    Arguments:\n",
    "    analysis: Either 'seq length' or 'errors'. Depending on the word is the \n",
    "    barplot that is going to be created.\n",
    "\n",
    "    Returns:\n",
    "    Amn object 'p' with the information to create a barplot with error bars of \n",
    "    the digit span test. \n",
    "    \n",
    "    Author:\n",
    "    Karina Diaz\n",
    "    '''\n",
    "\n",
    "\n",
    "    df = digit_mean_sem[digit_mean_sem.index.get_level_values(0).isin(participants)]\n",
    "    # Data for the barplots\n",
    "    participants = df.reset_index().participant.unique().tolist()\n",
    "    sessions_type = df.reset_index().type.unique().tolist()\n",
    "    values = df[analysis]['mean'].tolist()\n",
    "\n",
    "    # Data for the error bars\n",
    "    upper = df[analysis]['mean'] + 1.96 * df[analysis]['sem']\n",
    "    lower = df[analysis]['mean'] - 1.96 * df[analysis]['sem']\n",
    "    data = pd.concat([upper.rename(\"upper\"), lower.rename(\"lower\")], axis=1)\n",
    "\n",
    "    # Dictionary to change the y labels\n",
    "    y_label = {'seq length': 'Number of digits',\n",
    "              'errors':'Number of errors ',\n",
    "              'clicks difference': 'Diference in errors made'}\n",
    "    # Dictionary to change the plot titles\n",
    "    title = {'seq length': 'Digit Span - Longest average sequence remembered',\n",
    "              'errors':'Digit Span - Average number of errors made',\n",
    "              'clicks difference': 'Digit Span - Average diference in errors made'}\n",
    "\n",
    "    x = [(participant, session) for participant in participants for session in sessions_type]\n",
    "    source = ColumnDataSource(data=dict(x=x, counts=values))\n",
    "    \n",
    "    # Create the barplots\n",
    "    p = figure(x_range=FactorRange(*x), height=400, title=title[analysis])\n",
    "    # Customise barplots\n",
    "    p.vbar(x='x', top='counts', source=source, line_color=line_color,\n",
    "        fill_color=factor_cmap('x', palette=colors, factors=sessions_type, \n",
    "        start=1, end=2))\n",
    "\n",
    "    # Customise x-axis\n",
    "    p.xaxis.axis_label = \"Participant, Sesion type\"\n",
    "    p.x_range.range_padding = 0.1\n",
    "    p.xaxis.major_label_orientation = 1\n",
    "    p.xgrid.grid_line_color = None\n",
    "\n",
    "    # Customise y-axis\n",
    "    p.yaxis.axis_label = y_label[analysis]\n",
    "    p.y_range.start = 0\n",
    "    p.yaxis.major_label_orientation = \"vertical\"\n",
    "    p.y_range.range_padding = 1\n",
    "    \n",
    "    # Run the function to add the error bars\n",
    "    p = plot_standard_error(plot=p, data=data)\n",
    "    return (p)\n",
    "\n",
    "digit_seq_plot = digit_barplots('seq length', participants)\n",
    "show(digit_seq_plot )\n",
    "\n",
    "digit_error_plot = digit_barplots('errors', participants)\n",
    "show(digit_error_plot)\n",
    "\n",
    "# # Making interactive the plots \n",
    "#analyses = ['seq length', 'errors']\n",
    "#inter_plot = pn.interact(digit_barplots, analysis=analyses)\n",
    "#inter_plot\n",
    "\n",
    "# # Creating a dashboard\n",
    "# dashboard = pn.template.BootstrapTemplate(title='Title', sidebar_with = 400)\n",
    "# dashboard.sidebar.append(inter_plot[0])\n",
    "# dashboard.main.append(inter_plot[1])\n",
    "# dashboard.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise all the results a dashboard i made using Panel (holoviz). The idea was to have a different page for each test and a page for the health data. This idea is implemented using a Dashboard class, where the user can add pages with contents. It will automatically create a sidebar navigation when a page is added. The class can also be used in other projects to create other dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = '''\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque augue eros, tristique ut eros et, bibendum mattis tellus. Integer dui sapien, pulvinar nec ante nec, rutrum feugiat massa. Fusce tristique viverra nunc, sed commodo orci rhoncus sed. Aliquam pellentesque dui lectus, vel gravida eros volutpat vitae. Aliquam faucibus nulla id dolor suscipit elementum. Donec sed ante hendrerit, porta ligula faucibus, venenatis mi. Donec id imperdiet neque. Ut vel blandit urna. Fusce convallis, eros at suscipit aliquam, quam tellus pharetra est, ultrices ultrices dolor mi eu enim. Integer sed rutrum tellus.\n",
    "\n",
    "Etiam non commodo sem. Fusce faucibus tristique mauris, et fermentum quam euismod et. Vestibulum tempor mi neque, et consectetur odio tincidunt ut. Nunc scelerisque sed neque vitae efficitur. Nulla rutrum purus hendrerit, posuere massa ut, pharetra mi. Pellentesque nisi ipsum, pretium ut interdum eget, tempor at dui. Vestibulum a lectus est. Curabitur faucibus id neque ut pharetra. Proin rutrum aliquet scelerisque. Vestibulum id felis at eros accumsan commodo. Vestibulum nec sem felis. Aenean in ullamcorper diam.\n",
    "\n",
    "In commodo nisl turpis, id laoreet elit suscipit eu. Mauris ut interdum odio. Vivamus ultricies lorem ligula, ut consequat sapien tempor non. Aenean pellentesque nulla sit amet sem fermentum auctor. Nulla facilisi. Sed iaculis vehicula neque, sit amet tempor libero fringilla quis. Phasellus malesuada placerat elit nec vestibulum. Etiam eu odio imperdiet, ornare leo sed, suscipit magna. Proin diam ante, imperdiet eu odio ac, consectetur euismod ipsum. Vivamus non odio aliquet, dapibus elit sit amet, viverra diam. Proin posuere orci eget orci tempus, ut eleifend ipsum mattis. Fusce ultrices est vitae nibh aliquet sollicitudin. Duis vehicula erat turpis, ac efficitur turpis sagittis eget.\n",
    "\n",
    "Proin eros sapien, vestibulum at congue a, hendrerit sed lacus. Mauris aliquet egestas mauris, sit amet mattis velit faucibus convallis. Phasellus aliquam sapien eros, quis volutpat velit faucibus ut. Vestibulum pulvinar mollis orci vel fringilla. In dapibus, mi iaculis ornare tincidunt, lacus risus sollicitudin tortor, blandit eleifend tellus arcu id tortor. Cras nec fringilla nunc, a fermentum urna. Vivamus urna ligula, tempus nec dolor sed, fermentum faucibus velit. Nulla convallis vitae turpis in tempor.\n",
    "\n",
    "Integer non faucibus mi, vel gravida felis. Suspendisse vel mi felis. Curabitur dapibus enim ullamcorper consequat vulputate. Suspendisse scelerisque nibh ut luctus iaculis. Sed nunc urna, hendrerit vel sapien nec, imperdiet posuere felis. Cras varius nibh sed tortor congue, et egestas velit lacinia. Mauris purus magna, posuere vel metus non, tempus mattis lacus. Vestibulum turpis justo, posuere nec ante at, facilisis tristique dui. Aenean gravida, eros in luctus lobortis, ipsum lorem ornare felis, vel volutpat ipsum metus vitae erat. Aliquam condimentum aliquam ipsum, at aliquet quam congue quis. Phasellus eu metus velit.\n",
    "'''\n",
    "\n",
    "sample_text_small = '''\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque augue eros, tristique ut eros et, bibendum mattis tellus. Integer dui sapien, pulvinar nec ante nec, rutrum feugiat massa. Fusce tristique viverra nunc, sed commodo orci rhoncus sed. Aliquam pellentesque dui lectus, vel gravida eros volutpat vitae. Aliquam faucibus nulla id dolor suscipit elementum. Donec sed ante hendrerit, porta ligula faucibus, venenatis mi. Donec id imperdiet neque. Ut vel blandit urna. Fusce convallis, eros at suscipit aliquam, quam tellus pharetra est, ultrices ultrices dolor mi eu enim. Integer sed rutrum tellus.\n",
    "\n",
    "Etiam non commodo sem. Fusce faucibus tristique mauris, et fermentum quam euismod et. Vestibulum tempor mi neque, et consectetur odio tincidunt ut. Nunc scelerisque sed neque vitae efficitur. Nulla rutrum purus hendrerit, posuere massa ut, pharetra mi. Pellentesque nisi ipsum, pretium ut interdum eget, tempor at dui. Vestibulum a lectus est. Curabitur faucibus id neque ut pharetra. Proin rutrum aliquet scelerisque. Vestibulum id felis at eros accumsan commodo. Vestibulum nec sem felis. Aenean in ullamcorper diam.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create participant options buttons\n",
    "# red_btn = pn.widgets.Toggle(name='Red', value=True, width=100, css_classes=['red_button'])\n",
    "# orange_btn = pn.widgets.Toggle(name='Orange', value=True, width=100, css_classes=['orange_button'])\n",
    "# green_btn = pn.widgets.Toggle(name='Green', value=True, width=100, css_classes=['green_button'])\n",
    "# blue_btn = pn.widgets.Toggle(name='Blue', value=True, width=100, css_classes=['blue_button'])\n",
    "# pink_btn = pn.widgets.Toggle(name='Pink', value=True, width=100, css_classes=['pink_button'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dashboard:\n",
    "    '''\n",
    "    This class creates a panel dashboard to which pages can be added\n",
    "    \n",
    "    Arguments: \n",
    "    title (str): title of the dashboard\n",
    "    header_color (str): name of a color or hex color code\n",
    "    css (str): raw css\n",
    "    \n",
    "    Returns:    \n",
    "    dashboard object\n",
    "    \n",
    "    Author(s): \n",
    "    Job Maathuis\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, title: str, header_color: str, css):\n",
    "        # initialise dashboard\n",
    "        self.dashboard = pn.template.BootstrapTemplate(title=title, header_background=header_color, sidebar_width=200)\n",
    "        self.dashboard.main.extend([pn.pane.Markdown(''), pn.Column(width=1000)]) \n",
    "        self.main_page = self.dashboard.main[1]\n",
    "        pn.extension(raw_css=[css])\n",
    "        \n",
    "        # variable to save all the pages\n",
    "        self.pages = {}\n",
    "        \n",
    "    def add_page(self, title: str, show_page: bool, *contents):\n",
    "        ''' Adds a page to the dashboards and create a sidebar navigation button for it '''\n",
    "        sidebar_button = pn.widgets.Button(name=title, width=150, css_classes=['sidebar_button'])  # create sidebar button\n",
    "        self.dashboard.sidebar.append(sidebar_button)  # append button to sidebar\n",
    "        sidebar_button.on_click(self._update_page)  # callback\n",
    "        self.pages[title] = [*contents]  # add the contents to the page dictionary\n",
    "        if show_page:\n",
    "            self._show_page(title)\n",
    "    \n",
    "    def _update_page(self, event):\n",
    "        ''' private callback method to update the page when a sidebar button is clicked '''\n",
    "        name = event.obj.name  # extract name from event\n",
    "        self.main_page.clear()  # clear the main page\n",
    "        self.main_page.append(pn.pane.Markdown(f'##{name}'))  # create title\n",
    "        self.main_page.extend([item for item in self.pages[name]])  # add all of the contents to the page\n",
    "        \n",
    "    def _show_page(self, title: str):\n",
    "        ''' private method that show the page of the given page title '''\n",
    "        self.main_page.clear()\n",
    "        self.main_page.append(pn.pane.Markdown(f'##{title}'))\n",
    "        self.main_page.extend([item for item in self.pages[title]])\n",
    "            \n",
    "    def show(self):\n",
    "        ''' shows the dashboard ''' \n",
    "        self.dashboard.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the class is made, it can be called. However, first the CSS need to be made, which defines the markup of the page. And also the interactive plots need to be defined, so that they can be added to pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSS styling\n",
    "css = '''\n",
    ".bk {\n",
    "    margin-left: 80px;\n",
    "}\n",
    "\n",
    ".sidebar_button .bk-btn-group button {\n",
    "    border-radius: 6px;\n",
    "    font-weight: bolder;\n",
    "}\n",
    "\n",
    ".option_button .bk-btn-default.bk-active {\n",
    "    background-color: #00dcff38;\n",
    "    font-weight: bold;\n",
    "    border-color: black;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_toggle():\n",
    "    return  pn.widgets.CheckButtonGroup(options=['red', 'orange', 'blue', 'green', 'pink'],\n",
    "                                        value  =['red', 'orange', 'blue', 'green', 'pink'],\n",
    "                                        width  =600, css_classes=['option_button'])\n",
    "\n",
    "# create widgets\n",
    "toggle_digit_length = create_toggle()\n",
    "toggle_digit_errors = create_toggle()\n",
    "toggle_verbal       = create_toggle()\n",
    "toggle_stop         = create_toggle()\n",
    "toggle_stroop_corr  = create_toggle()\n",
    "toggle_stroop_rt    = create_toggle()\n",
    "toggle_flanker      = create_toggle()\n",
    "radio_btn_flanker   = pn.widgets.RadioButtonGroup(options=['correct', 'incorrect'], value='correct',\n",
    "                                                  width=600, css_classes=['option_button'])\n",
    "\n",
    "\n",
    "\n",
    "# bind widgets to plots\n",
    "digit_barplot_length   = pn.bind(digit_barplots, analysis='seq length', participants=toggle_digit_length)\n",
    "digit_barplot_errors   = pn.bind(digit_barplots, analysis='errors', participants=toggle_digit_errors)\n",
    "verbal_barplot         = pn.bind(pf.plot_error_bar, df=verbal_df, datacol='n', \n",
    "                                 title='Verbal Fluency Task - Number of words produced per participant, per session type',\n",
    "                                 xlabel='Participant, Session type', ylabel='Average words produced',\n",
    "                                 participants=toggle_verbal,)\n",
    "stop_barplot           = pn.bind(pf.plot_error_bar, df=stop_df, datacol='response_time', \n",
    "                                 title='Stop Signal Task - Average response time in go trials per participant, per session type', \n",
    "                                 xlabel='Participant, Session type',ylabel='Average response time (ms)',\n",
    "                                 participants=toggle_stop)\n",
    "stroop_correct_barplot = pn.bind(stroop_status_plot_error, participants=toggle_stroop_corr)\n",
    "stroop_rt_barplot      = pn.bind(stroop_plot_error_bar, participants=toggle_stroop_rt)\n",
    "flanker_barplot        = pn.bind(flanker_plot_error, answer_type=radio_btn_flanker, participants=toggle_flanker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = ['red', 'orange', 'green', 'blue', 'pink']\n",
    "targets = [\"heartrate\", \"calories\", \"temperature\"]\n",
    "\n",
    "hydrohomies_db = Dashboard('HydroHomies', '#00C9FF', css)\n",
    "hydrohomies_db.add_page('Home',                True, sample_text)\n",
    "hydrohomies_db.add_page('Stroop test',         False, toggle_stroop_corr, stroop_correct_barplot, sample_text_small,\n",
    "                                                      toggle_stroop_rt,   stroop_rt_barplot, sample_text_small)\n",
    "hydrohomies_db.add_page('Stop signal test',    False, toggle_stop, stop_barplot, sample_text_small)\n",
    "hydrohomies_db.add_page('Flanker test',        False, radio_btn_flanker, toggle_flanker, flanker_barplot, sample_text_small)\n",
    "hydrohomies_db.add_page('Digit span test',     False, toggle_digit_length, digit_barplot_length, sample_text_small,\n",
    "                                                      toggle_digit_errors, digit_barplot_errors, sample_text_small)\n",
    "hydrohomies_db.add_page('Verbal fluency test', False, toggle_verbal, verbal_barplot, sample_text_small)\n",
    "hydrohomies_db.add_page('Health data',         False, pn.interact(show_personal_plot, participant=participants, target = targets),  sample_text_small, pn.interact(personal_plot_error_bar, target = targets), sample_text_small)\n",
    "hydrohomies_db.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we want to approve or reject our hypotheses. To achieve this, first we start to gather all the relavant datasets from different tests. then, try to find their distribution (try to make a normalized data set out of them). Finally, we will use the proper statistical test in order to approve or reject our hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language\n",
    "We expect the verbal production in words per second to decrease under the influence of dehydration.\n",
    "\n",
    "#### Executive function\n",
    "We expect the verbal inhibition accuracy and words per second to both decrease under the influence of dehydration.\n",
    "\n",
    "#### Complex attention\n",
    "We expect the selective attention accuracy to decrease under the influence of dehydration.\n",
    "\n",
    "#### Perceptual-motor function\n",
    "We expect the psychomotor reaction time in ms to increase and accuracy to decrease under the influence of dehydration.\n",
    "\n",
    "#### Learning and memory\n",
    "We expect the recall accuracy to decrease under the influence of dehydration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a statistical Dataframe\n",
    "making a statistic database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.special import digamma\n",
    "from scipy.stats import norm, poisson, binom, gamma\n",
    "from scipy.stats import iqr\n",
    "from scipy.stats import ttest_rel, ttest_ind, wilcoxon\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a digit span dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_df = data_dict[\"digit\"]\n",
    "digit_df = digit_df.astype({'participant': 'string',\n",
    "                                'type': 'string',\n",
    "                                'repeat': 'int',\n",
    "                                'seq length':'float',\n",
    "                                'errors': 'float',\n",
    "                                'clicks expected': 'float',\n",
    "                                'clicks observed': 'float'})\n",
    "digit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making a statistic database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_df_maker(flanker_df, stroop_df, stop_df, verbal_df, digit_df):\n",
    "    \"\"\"\n",
    "    explanation: This function makes a dataframe for statistical analysis \n",
    "                 based on previous refined dataframes.\n",
    "    input: flanker_df, stroop_df, stop_df, verbal_df, digit_df\n",
    "    output: statistical dataframe (stat_df)\n",
    "    \n",
    "    \"\"\"\n",
    "    # add response time and error from Flanker test\n",
    "    stat_df = pd.DataFrame(flanker_df.iloc[:,[0,1,2,5,6]].\\\n",
    "        rename(columns = {\"correctness\":\"correctness\",\"response-time\":\"response\"}).\\\n",
    "        groupby('participant'))\n",
    "\n",
    "    # add response time and error from Stroop test\n",
    "    stroop_df_slice = pd.DataFrame(stroop_df.iloc[:,[0,1,2,7,8]].\\\n",
    "        rename(columns = {\"status\":\"correctness\",\"reaction_time\":\"response\"}).\\\n",
    "        groupby('participant'))\n",
    "    stat_df = stat_df.merge(stroop_df_slice, left_on=0, right_on=0)\n",
    "\n",
    "    # add response time and error from Stop Signal test\n",
    "    stop_df_slice = pd.DataFrame(stop_df.iloc[:,[0,1,2,6,7]].\\\n",
    "        rename(columns = {\"status\":\"correctness\", \"response_time\":\"response\"}).\\\n",
    "        groupby('participant'))\n",
    "    stat_df = stat_df.merge(stop_df_slice, left_on=0, right_on=0)\n",
    "\n",
    "    # add number of words per test from Verbal Fluency test\n",
    "    verbal_df_slice = pd.DataFrame(verbal_df.rename(columns = {\"n\":\"response\"}).\\\n",
    "        groupby('participant'))\n",
    "    stat_df = stat_df.merge(verbal_df_slice, left_on=0, right_on=0)\n",
    "\n",
    "    #add sequence length from Digit Span test\n",
    "    digit_df_slice = pd.DataFrame(digit_df.iloc[:,:5].rename(columns = {\"seq length\":\"response\"}).\\\n",
    "        groupby('participant'))\n",
    "    stat_df = stat_df.merge(digit_df_slice, left_on=0, right_on=0)    \n",
    "                                           \n",
    "    stat_df.columns = ['colour', 'flanker', 'stroop', 'stop', 'verbal', 'digit']\n",
    "\n",
    "    return stat_df\n",
    "\n",
    "stat_df = stat_df_maker(flanker_df, stroop_df, stop_df, verbal_df, digit_df)\n",
    "stat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions\n",
    "Pearson Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_distribution(test, data_type, counter, number):\n",
    "\n",
    "    \"\"\"\n",
    "    lisence: written by Hooman Bahrdo\n",
    "    explanation: This function gives a pearson distribution based on our data frames.\n",
    "    input: 1- test name \n",
    "           2- data type can be normalized and raw here\n",
    "           3- counter: number of participant\n",
    "           4- number: control(0), degydration(1)\n",
    "    output: 1- normalized distribution\n",
    "            2- raw (gamma) distribution \n",
    "    \"\"\"\n",
    "    # catagorize the data set based on its type(dehydration, control)\n",
    "    df = stat_df[test][counter]\n",
    "    df_type = pd.DataFrame(df.groupby('type'))\n",
    "\n",
    "    # for digit span find the maximum sequence length and extract raw \n",
    "    # distribution and normalized one\n",
    "    if test == 'digit':\n",
    "        df_control = pd.DataFrame(df_type[1][0].groupby('repeat').max())['response']\n",
    "        df_dehydration = pd.DataFrame(df_type[1][1].groupby('repeat').max())['response']\n",
    "\n",
    "        # normalized data\n",
    "        df_difference = ((df_control.iloc[:int((len(df_control)/2))].reset_index() +\\\n",
    "            df_control.iloc[int((len(df_control)/2)):].reset_index()) / 2. -\\\n",
    "            (df_dehydration.iloc[:int((len(df_dehydration)/2))].reset_index() +\\\n",
    "            df_dehydration.iloc[int((len(df_dehydration)/2)):].reset_index()) / 2.).dropna() \n",
    "        \n",
    "        # return normalized distribution for digit test \n",
    "        if re.search('^norm', data_type):\n",
    "            return df_difference['response']   \n",
    "        \n",
    "        # return raw distribution (gamma distribution)for digit test  \n",
    "        else:\n",
    "            return pd.DataFrame(df_type[1][number].groupby('repeat').max())['response']\n",
    "    \n",
    "    # extract raw distribution and normalized one for other datasets\n",
    "    else:\n",
    "        df_control = df_type[1][0]['response'].dropna()\n",
    "        df_dehydration = df_type[1][1]['response'].dropna()\n",
    "\n",
    "        # make the normalized distribution\n",
    "        df_difference = ((df_control.iloc[:int((len(df_control)/2))] +\\\n",
    "            df_control.iloc[int((len(df_control)/2)):]) / 2. -\\\n",
    "            (df_dehydration.iloc[:int((len(df_dehydration)/2))] +\\\n",
    "            df_dehydration.iloc[int((len(df_dehydration)/2)):]) / 2.).dropna()  \n",
    "\n",
    "        # return normalized distribution \n",
    "        if re.search('^norm', data_type):\n",
    "            return df_difference  \n",
    "        \n",
    "        # return raw distribution (gamma distribution)\n",
    "        else:\n",
    "            return df_type[1][number]['response'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binomial Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_distribution(test, counter, number):\n",
    "\n",
    "    \"\"\"\n",
    "    lisence: written by Hooman Bahrdo\n",
    "    explanation: This function gives properties of binomial distribution (k, p) \n",
    "                 for data frames that has TWO states.\n",
    "    input: 1- test name \n",
    "           3- counter: number of participant\n",
    "           4- number: control(0), degydration(1)\n",
    "    output: 1- bionomial distribution properties:k, p\n",
    "    \"\"\"\n",
    "\n",
    "    # choose the proper dataframe based on the test name and number of participants\n",
    "    bin = []\n",
    "    df = stat_df[test][counter]\n",
    "    df_type = pd.DataFrame(df.groupby('type'))\n",
    "\n",
    "    df = df_type[1][number]\n",
    "\n",
    "    # exempt Flanker test as it has different two state data(correct, incorrect)\n",
    "    if test == 'flanker':\n",
    "        incorrect_number = len(df[df['correctness'] != 'correct'])\n",
    "\n",
    "    else:\n",
    "        incorrect_number = len(df[df['correctness'] != 1])\n",
    "\n",
    "    # we can suppose that the number of tests is the k_value if we consider\n",
    "    # each person seperately as a population\n",
    "    k = len(df)\n",
    "    bin.append(k)\n",
    "    p = incorrect_number / len(df)\n",
    "    bin.append(p)\n",
    "\n",
    "    return bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma Distribution parameters in different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_parameters(df):\n",
    "\n",
    "    \"\"\"\n",
    "    license: this function is constructed base on Dr. APOL'S CODES.\n",
    "             but it is converted to a function for specific purpose by Hooman Bahrdo.\n",
    "    explanation: this function give the a GAMMA dataframe, and calculate all the relevant\n",
    "                 parameters and variables.\n",
    "    input: 1- dataframe\n",
    "    output: 1- avarage (y_av)\n",
    "            2- mu parameter (Robust method) (mu_R)\n",
    "            3- probability distribution function (Maximum Likelihood) (f_ML)\n",
    "            4- probability distribution function (Method of Moments) (f_MM)\n",
    "            5- x range (x)\n",
    "            6- ML name (first_method)\n",
    "            7- MM name (second_method)\n",
    "    \"\"\"\n",
    "\n",
    "    method_parameters_list = []\n",
    "\n",
    "    # calculate mean value and varians\n",
    "    first_method ='ML'\n",
    "    second_method ='MM' \n",
    "    y_av = np.mean(df)\n",
    "    lny_av = np.mean(np.log(df))\n",
    "    m_2 = np.mean((df - y_av)**2)\n",
    "    Delta = np.log(y_av) - lny_av\n",
    "\n",
    "    # calculate robust method parameters\n",
    "    mu_R = np.median(df) \n",
    "    sigma_R = iqr(df)/1.349\n",
    "\n",
    "    # Define function(s) to find the root(s) of:\n",
    "    def ML_a(a, Delta):\n",
    "        return np.log(a) - digamma(a) - Delta\n",
    "\n",
    "    # MM estimates:\n",
    "    # sparse data set in digit span test \n",
    "    try:\n",
    "        a_MM = y_av**2 / m_2\n",
    "        theta_MM = y_av / m_2\n",
    "    except ZeroDivisionError:\n",
    "        a_MM = 0\n",
    "        theta_MM = 0\n",
    "\n",
    "    method_parameters_list.append(a_MM)\n",
    "    method_parameters_list.append(theta_MM)\n",
    "\n",
    "    # Use a_MM as initial guess for a in fsolve function:\n",
    "    sol = fsolve(ML_a, a_MM, Delta)\n",
    "    a_ML = sol[0]\n",
    "\n",
    "    theta_ML = a_ML / y_av\n",
    "\n",
    "\n",
    "    method_parameters_list.append(a_ML)\n",
    "    method_parameters_list.append(theta_ML)\n",
    "\n",
    "    # Plot ML estimate of Gamma(a, theta) distribution:\n",
    "    x = np.linspace(np.min(df), np.max(df), 501)\n",
    "    f_ML = np.array([gamma.pdf(xi, a_ML, loc=0, scale=1/theta_ML) for xi in x])\n",
    "\n",
    "    # sparse data set in digit span test \n",
    "    try:\n",
    "        f_MM = np.array([gamma.pdf(xi, a_MM, loc=0, scale=1/theta_MM) for xi in x])\n",
    "    except ZeroDivisionError:\n",
    "        f_MM =0\n",
    "        \n",
    "    return y_av, mu_R, f_ML, f_MM, x, first_method, second_method, method_parameters_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Distribution parameters in different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_parameters(df):\n",
    "\n",
    "     \"\"\"\n",
    "     license: this function is constructed base on Dr. APOL'S CODES.\n",
    "             but it is converted to a function for specific purpose by Hooman Bahrdo.\n",
    "     explanation: this function give the a Normal dataframe, and calculate all the relevant\n",
    "                 parameters and variables.\n",
    "     input: 1- dataframe\n",
    "     output: 1- avarage (mu_ML)\n",
    "            2- mu parameter (Robust method) (mu_R)\n",
    "            3- probability distribution function (Maximum Likelihood) (f_N_ML)\n",
    "            4- probability distribution function (Robust Method) (f_N_R)\n",
    "            5- x range (x)\n",
    "            6- ML name (first_method)\n",
    "            7- MM name (second_method)\n",
    "     \"\"\"\n",
    "\n",
    "    # calculate robust method parameters\n",
    "     first_method ='ML'\n",
    "     second_method ='R' \n",
    "     mu_R = np.median(df) \n",
    "     sigma_R = iqr(df)/1.349\n",
    "\n",
    "    # calculate Maximum Likelihood parameters\n",
    "     mu_ML = np.mean(df)\n",
    "     sigma2_ML = np.mean((df - mu_ML)**2)\n",
    "     sigma_ML = np.sqrt(sigma2_ML)\n",
    "\n",
    "     # handle ZeroDivisionError when sigma2_ML=0 (lack of data points)\n",
    "     try:\n",
    "          s2 = len(df)/(len(df)-1) * sigma2_ML\n",
    "          s = np.sqrt(s2)\n",
    "     except ZeroDivisionError:\n",
    "          s2 = 0\n",
    "          s = 0\n",
    "     \n",
    "     # make x range based on the data frame\n",
    "     x = np.linspace(df.min()-(df.max()/10), df.max()+(df.max()/10), 201)\n",
    "\n",
    "     # ML normal distribution:\n",
    "     f_N_ML = np.array([norm.pdf(xi, loc = mu_ML, scale = s) for xi in x])\n",
    "     # robust normal distribution:\n",
    "     f_N_R = np.array([norm.pdf(xi, loc = mu_R, scale = sigma_R) for xi in x])\n",
    "\n",
    "     return mu_ML, mu_R, f_N_ML, f_N_R, x, first_method, second_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assistant Functions\n",
    "this function investigate the normality of a distibution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_normal(df, upper, lower):\n",
    "     \n",
    "    \"\"\"\n",
    "    license: written by Hooman Bahrdo.\n",
    "    explanation: this function give the a Normal dataframe, upper and lower bonf of \n",
    "                 its 95 CI, and find what pecentage of a dataframe locate inside this\n",
    "                 interval.\n",
    "    input: 1- dataframe\n",
    "           2- upper limit \n",
    "           3- lower limit\n",
    "    output: 1- normality status\n",
    "    \"\"\"\n",
    "    # check whether each point exists between intervals\n",
    "    i = 0\n",
    "    for counter, data in enumerate(df):\n",
    "\n",
    "        if data >= lower[counter] and data <=upper[counter]:\n",
    "            i += 1\n",
    "\n",
    "    normal_finder = i/len(df)\n",
    "\n",
    "    # chcke which range best describes this distribution\n",
    "    if normal_finder >= 0.95:\n",
    "        description = 'Normal > 95%'\n",
    "    elif normal_finder < 0.95 and normal_finder>=0.9:\n",
    "        description = 'Normal > 90%'\n",
    "    elif normal_finder < 0.9 and normal_finder >= 0.8:\n",
    "        description = 'Normal > 80%'   \n",
    "    else:\n",
    "        description = 'not Normal'\n",
    "        \n",
    "    return description         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function add label to plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_label(data_type, sub_plot, i, j, plot_type):\n",
    "\n",
    "    \"\"\"\n",
    "    license: Written by Hooman Bahrdo\n",
    "    explanation: This function add labels to the plot\n",
    "    input:  1- data_type\n",
    "            2- sub plot \n",
    "            3- i: number of raw\n",
    "            4- j: number of column\n",
    "            5- type of plot\n",
    "    output: some labels to x and y axis\n",
    "    \"\"\"\n",
    "    \n",
    "    # draw labels for normal and raw data  \n",
    "    if re.search('^norm|^raw', data_type):\n",
    "        if j == 0 and re.search('^his', plot_type):\n",
    "            sub_plot[i,j].set(ylabel='frequency')\n",
    "\n",
    "        elif j == 0 and re.search('^Q_Q', plot_type):\n",
    "            sub_plot[i,j].set(ylabel='Sample quantiles')\n",
    "\n",
    "        if i == 1 and re.search('^his', plot_type):\n",
    "            sub_plot[i,j].set(xlabel='reponse time difference')\n",
    "                \n",
    "        elif i == 1 and re.search('^Q_Q', plot_type):\n",
    "            sub_plot[i,j].set(xlabel='Theoretical quantiles')\n",
    "\n",
    "    # draw labels for error data  \n",
    "    else:\n",
    "        if j == 0:\n",
    "            sub_plot[i,j].set(ylabel='Probability')\n",
    "\n",
    "        if i == 1 :\n",
    "            sub_plot[i,j].set(xlabel='Random Variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n",
    "Binomial plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_plot(df, sub_plot,counter_1, counter_2, color):\n",
    "\n",
    "    \"\"\"\n",
    "    license: this function is constructed base on one of the Dr. APOL'S FUNCTIONS.\n",
    "             but most of it is written by Hooman Bahrdo.\n",
    "    explanation: this function give the properties of a binomial distribution and \n",
    "                 skethch its plot.\n",
    "    input: 1- dataframe\n",
    "           2- sub plot \n",
    "           3- counter1: number of raw\n",
    "           4- counter2: number of column\n",
    "           5- color of participant\n",
    "    output: 1- bionomial distribution (k, p) plot\n",
    "    \"\"\"\n",
    "\n",
    "    # Make binomial distribution:\n",
    "    k, p = df[0], df[1]\n",
    "\n",
    "    # Normal approximation:\n",
    "    mu = k*p\n",
    "    sigma = np.sqrt(k*p*(1-p))\n",
    "\n",
    "    # Make a plot:\n",
    "    i = list(range(k+3))\n",
    "    f_i = np.array([binom.pmf(xi, k, p) for xi in i])\n",
    "    x = np.linspace(np.min(i),np.max(i)+1,501)\n",
    "\n",
    "    # if mu>5 and k-mu>5, then we can consider our distribution as a normal distribution.\n",
    "    # otherwise, we should consider our distribution as poisson distribution. (Bagui & Mehra 2017)\n",
    "    if mu>5 and k-mu>5:\n",
    "        f = np.array([norm.pdf(xi, mu, sigma) for xi in x])\n",
    "\n",
    "    else:\n",
    "        # Corresponding parameter of the Pois(lambda) distribution:\n",
    "        lamb = k*p\n",
    "        f = np.array([poisson.pmf(xi, lamb) for xi in x])\n",
    "\n",
    "    # set label for index once\n",
    "    if counter_1 == 0 and counter_2 == 0:\n",
    "        sub_plot.vlines(i, 0, f_i, colors='k', linestyles='-', lw=1,label='Simulated Distribution')\n",
    "        sub_plot.plot(x, f, 'r', label='Approximation Curve')\n",
    "        sub_plot.set_title(color, color=color, fontsize='xx-large') \n",
    "        sub_plot.text(0.8, 0.9, f'k= {round(k,2)}, p= {round(p,2)}', horizontalalignment='center',\\\n",
    "                       verticalalignment='center', transform=sub_plot.transAxes, fontsize='xx-large')\n",
    "        \n",
    "        # impose x range        \n",
    "        for number in range(501):\n",
    "            if f[number] < 1e-3 and x[number] > i[int(k/5)]:\n",
    "                sub_plot.set_xlim([x[0],x[number+10]])\n",
    "                break\n",
    "        \n",
    "    else: \n",
    "        sub_plot.vlines(i, 0, f_i, colors='k', linestyles='-', lw=1)\n",
    "        sub_plot.plot(x, f, 'r')\n",
    "        sub_plot.set_title(color, color=color, fontsize='xx-large') \n",
    "        sub_plot.text(0.8, 0.9, f'k= {round(k,2)}, p= {round(p,2)}', horizontalalignment='center',\\\n",
    "                       verticalalignment='center', transform=sub_plot.transAxes, fontsize='xx-large')\n",
    "        \n",
    "        # impose x range\n",
    "        for number in range(501):\n",
    "            if f[number] < 1e-5 and x[number] > i[int(k/5)]:\n",
    "                sub_plot.set_xlim([x[0],x[number+10]])\n",
    "                break\n",
    "\n",
    "    return sub_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(df, sub_plot, color, i, j, data_type):\n",
    "    \n",
    "     \"\"\"\n",
    "     license: the function's structure is inspired by one of the Dr. APOL'S FUNCTIONS.\n",
    "             but is written by Hooman Bahrdo.\n",
    "     explanation: this function gives the distribution and its type, then\n",
    "                 skethches its plot.\n",
    "     input: 1- dataframe\n",
    "            2- sub plot \n",
    "            3- color of participant\n",
    "            4- i: number of raw\n",
    "            5- j: number of column\n",
    "            6- data_type: raw or normalized data \n",
    "  \n",
    "     output: 1- histogram and its probability distribution funcion plot\n",
    "     \"\"\"     \n",
    "\n",
    "     if re.search('^norm', data_type):\n",
    "          mu_ML, mu_R, f_ML, f_R, x, name_1, name_2= normal_parameters(df)\n",
    "     else:\n",
    "          mu_ML, mu_R, f_ML, f_R, x, name_1, name_2 = gamma_parameters(df)\n",
    "     \n",
    "     # extract the distribution name\n",
    "     name = re.split('/s', data_type) \n",
    "     distribution_name = name[0]\n",
    "\n",
    "     #make just one lable for the legend\n",
    "     if i == 0 and j ==0:\n",
    "          sub_plot.hist(x=df, density=True, bins='auto', \n",
    "               color='darkgrey',alpha=1, rwidth=1, label='experimental data')\n",
    "          sub_plot.set_title(color, color=color, fontsize='xx-large')\n",
    "\n",
    "          sub_plot.grid(axis='y', alpha=0.5)\n",
    "          # sparse data set in digit span test \n",
    "          try:\n",
    "               sub_plot.plot(x, f_ML, 'r', label=f'{distribution_name} Distribution {name_1}')\n",
    "               sub_plot.plot(x, f_R, 'b', label=f'{distribution_name} Distribution {name_2}')\n",
    "          except ValueError:\n",
    "               pass\n",
    "          \n",
    "          sub_plot.axvline(x = mu_ML, color='red', linestyle='--', label='dataframe mean value')\n",
    "          sub_plot.axvline(x = mu_R, color='blue', linestyle='--', label='$\\mu$ Robust Theory')\n",
    "\n",
    "     else:\n",
    "          sub_plot.hist(x=df, density=True, bins='auto', \n",
    "               color='darkgrey',alpha=1, rwidth=1)\n",
    "          sub_plot.set_title(color, color=color, fontsize='xx-large')  \n",
    "          sub_plot.grid(axis='y', alpha=0.5)\n",
    "\n",
    "          # sparse data set in digit span test \n",
    "          try:\n",
    "               sub_plot.plot(x, f_ML, 'r')\n",
    "               sub_plot.plot(x, f_R, 'b')\n",
    "          except ValueError:\n",
    "               pass\n",
    "\n",
    "          sub_plot.axvline(x = mu_ML, color='red', linestyle='--')\n",
    "          sub_plot.axvline(x = mu_R, color='blue', linestyle='--')    \n",
    "     \n",
    "     return sub_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q_Q Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DS_Q_Q_Plot(y, sub_plot, color, counter_1, counter_2, est = 'robust'):\n",
    "    \"\"\"\n",
    "    * Minor changes by Hooman Bahrdo.\n",
    "    *\n",
    "    Function DS_Q_Q_Plot(y, est = 'robust', **kwargs)\n",
    "    \n",
    "       This function makes a normal quantile-quantile plot (Q-Q-plot), also known\n",
    "       as a probability plot, to visually check whether data follow a normal distribution.\n",
    "    \n",
    "    Requires:            - \n",
    "     \n",
    "    Arguments:\n",
    "      y                  data array\n",
    "      est                Estimation method for normal parameters mu and sigma:\n",
    "                         either 'robust' (default), or 'ML' (Maximum Likelihood),\n",
    "                         or 'preset' (given values)\n",
    "      N.B. If est='preset' than the *optional* parameters mu, sigma must be provided:\n",
    "      mu                 preset value of mu\n",
    "      sigma              preset value of sigma\n",
    "      \n",
    "    Returns:\n",
    "      Estimated mu, sigma, n, and expected number of datapoints outside CI in Q-Q-plot.\n",
    "      Q-Q-plot\n",
    "      \n",
    "    Author:            M.E.F. Apol\n",
    "    Date:              2020-01-06, revision 2022-08-30\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(y)\n",
    "    \n",
    "    # Calculate order statistic:\n",
    "    y_os = np.sort(y)\n",
    "  \n",
    "    # Estimates of mu and sigma:\n",
    "    # ML estimates:\n",
    "    mu_ML = np.mean(y)\n",
    "    sigma2_ML = np.var(y)\n",
    "    sigma_ML = np.std(y) # biased estimate\n",
    "    s2 = np.var(y, ddof=1)\n",
    "    s = np.std(y, ddof=1) # unbiased estimate\n",
    "\n",
    "    # Robust estimates:\n",
    "    mu_R = np.median(y)\n",
    "    sigma_R = iqr(y)/1.349\n",
    "    \n",
    "    # Assign values of mu and sigma for z-transform:\n",
    "    if est == 'ML':\n",
    "        mu, sigma = mu_ML, s\n",
    "    elif est == 'robust':\n",
    "        mu, sigma = mu_R, sigma_R\n",
    "    else:\n",
    "        print('Wrong estimation method chosen!')\n",
    "        return()\n",
    "\n",
    "    \n",
    "    # Expected number of deviations (95% confidence level):\n",
    "    n_dev = np.round(0.05*n)\n",
    "         \n",
    "    # Perform z-transform: sample quantiles z.i\n",
    "    z_i = (y_os - mu)/sigma\n",
    "\n",
    "    # Calculate cumulative probabilities p.i:\n",
    "    i = np.array(range(n)) + 1\n",
    "    p_i = (i - 0.5)/n\n",
    "\n",
    "    # Calculate theoretical quantiles z.(i):\n",
    "    from scipy.stats import norm\n",
    "    z_th = norm.ppf(p_i, 0, 1)\n",
    "\n",
    "    # Calculate SE or theoretical quantiles:\n",
    "    SE_z_th = (1/norm.pdf(z_th, 0, 1)) * np.sqrt((p_i * (1 - p_i)) / n)\n",
    "\n",
    "    # Calculate 95% CI of diagonal line:\n",
    "    CI_upper = z_th + 1.96 * SE_z_th\n",
    "    CI_lower = z_th - 1.96 * SE_z_th\n",
    "\n",
    "    # find whether a distribution is normal\n",
    "    description = finding_normal(z_i, CI_upper, CI_lower)\n",
    "\n",
    "    # Make Q-Q plot:\n",
    "    if counter_1 == 0 and counter_2 ==0:\n",
    "        sub_plot.plot(z_th, z_i, 'o', color='k', label='experimental data')\n",
    "        sub_plot.plot(z_th, z_th, '--', color='r', label='normal line')\n",
    "        sub_plot.plot(z_th, CI_upper, '--', color='b', label='95% CI')\n",
    "        sub_plot.text(0.8, 0.1, description, horizontalalignment='center',\\\n",
    "                    verticalalignment='center', transform=sub_plot.transAxes,\\\n",
    "                    fontsize='xx-large')\n",
    "    else:\n",
    "        sub_plot.plot(z_th, z_i, 'o', color='k')\n",
    "        sub_plot.plot(z_th, z_th, '--', color='r')\n",
    "        sub_plot.plot(z_th, CI_upper, '--', color='b')\n",
    "        sub_plot.text(0.8, 0.1, description, horizontalalignment='center',\\\n",
    "                    verticalalignment='center', transform=sub_plot.transAxes,\\\n",
    "                    fontsize='xx-large')\n",
    "\n",
    "    sub_plot.plot(z_th, CI_lower, '--', color='b')\n",
    "    sub_plot.set_title(color, color=color, fontsize='xx-large') \n",
    "    return sub_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Making Functions\n",
    "This function make the requested plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_plots(df, color, sub_plot, plot_type, i, j, data_type):\n",
    "    \n",
    "    \"\"\"\n",
    "    license: Written by Hooman Bahrdo\n",
    "    explanation: This function makes sub plots based on plot type and data type\n",
    "    input:  1- dataframe\n",
    "            2- color of participant\n",
    "            3- sub plot \n",
    "            4- type of plot\n",
    "            5- i: number of raw\n",
    "            6- j: number of column\n",
    "            7- data_type: raw or normalized data \n",
    "  \n",
    "    output: a plot based on above information\n",
    "    \"\"\"\n",
    "\n",
    "    if plot_type == 'histogram':\n",
    "        fig = histogram(df, sub_plot, color, i, j,  data_type)\n",
    "\n",
    "    elif re.search('^Q_Q plot', plot_type):\n",
    "        estimate = re.split('\\s', plot_type)[-1]\n",
    "        fig = DS_Q_Q_Plot(df, sub_plot, color,i, j, estimate)\n",
    "    \n",
    "    elif plot_type == 'binomial plot':\n",
    "        fig = binomial_plot(df, sub_plot,i, j, color) \n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this function is a render for making plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_plot(test='digit', data_type= 'raw response data', plot_type='histogram'):\n",
    "\n",
    "    \"\"\"\n",
    "    lisence: written by Hooman Bahrdo\n",
    "    explanation: This function opens all files finds those that have data\n",
    "                 and erase rest of them. thenadd some property to data and \n",
    "                 use the plot function to sketch the data.\n",
    "    input: type of graph, x_axis, y_axis\n",
    "    output: a set of graphs\n",
    "    \"\"\"\n",
    "\n",
    "    # plot normal data for all participants\n",
    "    if data_type =='normalized response data':\n",
    "        fig, sub_plots = plt.subplots(2,3,figsize=(20, 10))\n",
    "\n",
    "        #erase empty plot\n",
    "        fig.delaxes(sub_plots[1,2])\n",
    "        fig.subplots_adjust(left= 0.05, right=0.9, top=0.95, bottom=0.04)\n",
    "\n",
    "        # move through sub_plots and sketch them\n",
    "        participant_num = 0\n",
    "        for counter in range(len(stat_df)):           \n",
    "            j = counter\n",
    "\n",
    "            # move through columns\n",
    "            for i in range(0,2):\n",
    "\n",
    "                if participant_num >= 5:\n",
    "                    break\n",
    "\n",
    "                #sketch the plot\n",
    "                making_plots(pearson_distribution(test, data_type, counter, j),\\\n",
    "                                stat_df['colour'][participant_num], sub_plots[i,j], plot_type, i, j, data_type)\n",
    "                participant_num += 1  \n",
    "             \n",
    "                # add lable to side graphs\n",
    "                adding_label(data_type, sub_plots, i, j, plot_type)\n",
    "\n",
    "            # for column number more than 2 exit the loop\n",
    "            if j>=2:\n",
    "                break\n",
    "    \n",
    "    # plot error and raw data\n",
    "    else:\n",
    "        fig, sub_plots = plt.subplots(2,5,figsize=(35,15))\n",
    "        fig.subplots_adjust(left=0.05, right=0.9, top=0.95, bottom=0.04)\n",
    "\n",
    "        # plot error part\n",
    "        if data_type == 'error':\n",
    "\n",
    "            # loop through sub_plots and sketch them\n",
    "            for counter in range(len(stat_df)):\n",
    "                j = counter\n",
    "         \n",
    "                for i in range(0,2): \n",
    "                    making_plots(binomial_distribution(test, counter, i),\\\n",
    "                                    stat_df['colour'][counter], sub_plots[i,j], plot_type, j, i, data_type)  \n",
    "\n",
    "                    # add lable to side graphs\n",
    "                    adding_label(data_type, sub_plots, i, j, plot_type)    \n",
    "\n",
    "        # plot raw data\n",
    "        else:\n",
    "\n",
    "            # loop through sub_plots and sketch them\n",
    "            for counter in range(len(stat_df)):\n",
    "                j = counter\n",
    "    \n",
    "                for i in range(0,2):\n",
    "                    making_plots(pearson_distribution(test, data_type, counter, i),\\\n",
    "                                    stat_df['colour'][counter], sub_plots[i,j], plot_type, j, i, data_type)  \n",
    "                    \n",
    "                    # add lable to side graphs\n",
    "                    adding_label(data_type, sub_plots, i, j, plot_type)  \n",
    "\n",
    "    # add some properties to the main plot\n",
    "    fig.suptitle(f'test= {test}, plot type= {plot_type}, data type= {data_type}', fontsize = 'xx-large')\n",
    "\n",
    "    if data_type == 'normalized response data':\n",
    "        fig.legend(loc=4, fontsize = 'xx-large') \n",
    " \n",
    "    else:  \n",
    "        fig.legend(loc=7, fontsize = 'xx-large')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(right=0.85) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make these plots interactive you can use these titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making an interactive plot (titles for interactive part)\n",
    "# you can use these titles if you want to make it interactive\n",
    "tests = ['flanker', 'stroop', 'stop', 'verbal', 'digit']\n",
    "plot_name =  ['histogram', 'Q_Q plot ML', 'Q_Q plot robust', 'binomial plot']\n",
    "data_type = ['normalized response data','raw response data','error']\n",
    "inter_plot = pn.interact(render_plot, test=tests, data_type=data_type, plot_type=plot_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Tests\n",
    "Two-sample T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a custom made 2-sample t-test function:\n",
    "\n",
    "def two_sample_ttest(y_1, y_2, equal_var = False, alternative = 'two.sided'):\n",
    "\n",
    "    \"\"\" \n",
    "    license: Written by dr. Apol and revised by Hooman Bahrdo to fit in this program\n",
    "    explanation: This function calculate t_sample and p_value of a two sample t-test\n",
    "    input:  1- control dataframe\n",
    "            2- dehydration dataframe\n",
    "            3- variance equality\n",
    "            4- test type (two.sided, less and greater)\n",
    "  \n",
    "    output: t sample and p value\n",
    "    \"\"\"\n",
    "\n",
    "    t_samp, p_value = ttest_ind(y_1, y_2, equal_var = equal_var)\n",
    "    if alternative == 'two.sided':\n",
    "        p_real = p_value\n",
    "    if alternative == 'less':\n",
    "        if t_samp <= 0:\n",
    "            p_real = p_value/2\n",
    "        else:\n",
    "            p_real = 1 - p_value/2\n",
    "    if alternative == 'greater':\n",
    "        if t_samp >= 0:\n",
    "            p_real = p_value/2\n",
    "        else:\n",
    "            p_real = 1 - p_value/2\n",
    "    return t_samp, p_real"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wilcoxon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wilcoxon_test(y_1, y_2, alternative = 'two.sided'):\n",
    "\n",
    "    \"\"\" \n",
    "    license: inspired from dr. Apol's function for t test and written by\n",
    "             Hooman Bahrdo to fit in this program.\n",
    "    explanation: This function calculate t_sample and p_value of a Wilcoxon test\n",
    "    input:  1- control dataframe\n",
    "            2- dehydration dataframe\n",
    "            3- variance equality\n",
    "            4- test type (two.sided, less and greater)\n",
    "  \n",
    "    output: t sample and p value for Wilcoxon\n",
    "    \"\"\"\n",
    "\n",
    "    t_samp, p_value = wilcoxon(y_1, y_2)\n",
    "    if alternative == 'two.sided':\n",
    "        p_real = p_value\n",
    "    if alternative == 'less':\n",
    "        if t_samp <= 0:\n",
    "            p_real = p_value/2\n",
    "        else:\n",
    "            p_real = 1 - p_value/2\n",
    "    if alternative == 'greater':\n",
    "        if t_samp >= 0:\n",
    "            p_real = p_value/2\n",
    "        else:\n",
    "            p_real = 1 - p_value/2\n",
    "    return(t_samp, p_real)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-sample z-test for proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion_ztest(y_1, y_2, equal_var = False, alternative = 'two.sided'):\n",
    "\n",
    "    \"\"\" \n",
    "    license: inspired from dr. Apol's function for t test and written by\n",
    "             Hooman Bahrdo to fit in this program.\n",
    "    explanation: This function calculate stat and p_value of a two sample \n",
    "                 z test for proportion.\n",
    "    input:  1- number of incorrect data points\n",
    "            2- number of total sample\n",
    "            3- variance equality\n",
    "            4- test type (two.sided, less and greater)\n",
    "  \n",
    "    output: t sample and p value for Wilcoxon\n",
    "    \"\"\"\n",
    "\n",
    "    t_samp, p_value = proportions_ztest(y_1, y_2)\n",
    "    if alternative == 'two.sided':\n",
    "        p_real = p_value\n",
    "    if alternative == 'less':\n",
    "        if t_samp <= 0:\n",
    "            p_real = p_value/2\n",
    "        else:\n",
    "            p_real = 1 - p_value/2\n",
    "    if alternative == 'greater':\n",
    "        if t_samp >= 0:\n",
    "            p_real = p_value/2\n",
    "        else:\n",
    "            p_real = 1 - p_value/2\n",
    "    return(t_samp, p_real)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main statistical test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_test(test, data_type, stat_df):\n",
    "\n",
    "    \"\"\" \n",
    "    license: written by Hooman Bahrdo.\n",
    "    explanation: This function gives the test name and data type and make a list of\n",
    "    stats and p values of statistical tests for each experimental test.\n",
    "    input:  1- test name\n",
    "            2- data type\n",
    "  \n",
    "    output: stat list p value list for statistical tests\n",
    "    \"\"\"\n",
    "\n",
    "    t_sample_list = []\n",
    "    p_real_list = []\n",
    "    t_sample_w_list = []\n",
    "    p_real_w_list = []\n",
    "    stat_list = []\n",
    "    p_value_z_list = []\n",
    "\n",
    "    # for raw response time calculate two_sample t_test and Wilcoxon test\n",
    "    if re.search('^raw', data_type):\n",
    "\n",
    "        # loop over all participant\n",
    "        for counter in range(len(stat_df)):\n",
    "            control_df = pearson_distribution(test, data_type, counter, 0)\n",
    "            dehydration_df = pearson_distribution(test, data_type, counter, 1)\n",
    "\n",
    "            t_sample, p_real = two_sample_ttest(control_df, dehydration_df, False, 'greater')\n",
    "            t_sample_w, p_real_w = wilcoxon_test(control_df, dehydration_df, 'greater')\n",
    "\n",
    "            # add to their lists\n",
    "            t_sample_list.append(round(t_sample,4))\n",
    "            p_real_list.append(round(p_real,4))\n",
    "            t_sample_w_list.append(round(t_sample_w,4))\n",
    "            p_real_w_list.append(round(p_real_w,4))\n",
    "\n",
    "        statistical_test_df = pd.DataFrame(\n",
    "        {'colour': stat_df['colour'],\n",
    "        't_value_ttest': t_sample_list,\n",
    "        'p_value_ttest': p_real_list,\n",
    "        'stat_wilcoxon_test': t_sample_w_list,\n",
    "        'p_value_wilcoxon_test': p_real_w_list\n",
    "        })\n",
    "\n",
    "        return statistical_test_df\n",
    "\n",
    "    # for error data calculate two sample z test for proportion\n",
    "    else:\n",
    "        # loop over all participant\n",
    "        for counter in range(len(stat_df)):\n",
    "            bin_1 = binomial_distribution(test, counter, 0)\n",
    "            bin_2 = binomial_distribution(test, counter, 1)\n",
    "\n",
    "            # make count and nobs\n",
    "            incorrect_1 = int(bin_1[0] * bin_1[1])\n",
    "            incorrect_2 = int(bin_2[0] * bin_2[1])\n",
    "            count = np.array([incorrect_1, incorrect_2])\n",
    "            nobs = np.array([bin_1[0], bin_2[0]])\n",
    "\n",
    "            stat, p_value_z = proportion_ztest(count, nobs, equal_var = False, alternative = 'greater')            \n",
    "            stat_list.append(round(stat,4))\n",
    "            p_value_z_list.append(round(p_value_z,4))\n",
    "        \n",
    "\n",
    "        statistical_test_df = pd.DataFrame(\n",
    "        {'colour': stat_df['colour'],\n",
    "        'stat_ztest': stat_list,\n",
    "        'p_value_ztest': p_value_z_list,\n",
    "       })\n",
    "\n",
    "        return statistical_test_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making tables\n",
    "making tabel for Gamma distribution parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_binomial_tabel(test, data_type, stat_df):\n",
    "\n",
    "    # make columns of the tabel\n",
    "    k_control_list = []\n",
    "    p_control_list = []\n",
    "    k_dehydration_list = []\n",
    "    p_dehydration_list = []    \n",
    "\n",
    "    # loop through each participant\n",
    "    for counter in range(len(stat_df)):\n",
    "        bin_control = binomial_distribution(test, counter, 0)\n",
    "        bin_dehydration = binomial_distribution(test, counter, 1)\n",
    "\n",
    "        k_control_list.append(round(bin_control[0],4))\n",
    "        p_control_list.append(round(bin_control[1],4))\n",
    "        k_dehydration_list.append(round(bin_dehydration[0],4))\n",
    "        p_dehydration_list.append(round(bin_dehydration[1],4))\n",
    "\n",
    "    binomial_parameters_tabel = pd.DataFrame(\n",
    "        {'colour': stat_df['colour'],\n",
    "        'k_control': k_control_list,\n",
    "        'p_control': p_control_list,\n",
    "        'k_dehydration': k_dehydration_list,\n",
    "        'p_dehydration': p_dehydration_list,\n",
    "        })\n",
    "    return binomial_parameters_tabel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making tabel for Gamma distribution parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_gamma_parameters_tabel(test, data_type, stat_df):\n",
    "\n",
    "    # make columns of the tabel\n",
    "    a_MM_list_control = []\n",
    "    theta_MM_list_control = []\n",
    "    a_ML_list_control = []\n",
    "    theta_ML_list_control = []\n",
    "    a_MM_list_dehydration = []\n",
    "    theta_MM_list_dehydration = []\n",
    "    a_ML_list_dehydration = []\n",
    "    theta_ML_list_dehydration = []\n",
    "\n",
    "    # loop through each participant\n",
    "    for counter in range(len(stat_df)):\n",
    "        control_df = pearson_distribution(test, data_type, counter, 0)\n",
    "        dehydration_df = pearson_distribution(test, data_type, counter, 1)\n",
    "\n",
    "        mu_ML_1, mu_R_1, f_ML_1, f_R_1, x_1, name1_1, name1_2,\\\n",
    "                                    parameters_list_1 = gamma_parameters(control_df)\n",
    "        mu_ML_2, mu_R_2, f_ML_2, f_R_2, x_2, name2_1, name2_2,\\\n",
    "                                    parameters_list_2 = gamma_parameters(dehydration_df)\n",
    "\n",
    "        # append the required data to tabel's columns\n",
    "        a_MM_list_control.append(round(parameters_list_1[0],4))\n",
    "        theta_MM_list_control.append(round(parameters_list_1[1],4))\n",
    "        a_ML_list_control.append(round(parameters_list_1[2],4))\n",
    "        theta_ML_list_control.append(round(parameters_list_1[3],4))\n",
    "        a_MM_list_dehydration.append(round(parameters_list_2[0],4))\n",
    "        theta_MM_list_dehydration.append(round(parameters_list_2[1],4))\n",
    "        a_ML_list_dehydration.append(round(parameters_list_2[2],4))\n",
    "        theta_ML_list_dehydration.append(round(parameters_list_2[3],4))\n",
    "\n",
    "    gamma_parameter_df = pd.DataFrame(\n",
    "        {'colour': stat_df['colour'],\n",
    "        'a_MM_control': a_MM_list_control,\n",
    "        'theta_MM_control': theta_MM_list_control,\n",
    "        'a_ML_control': a_ML_list_control,\n",
    "        'theta_ML_control': theta_ML_list_control,\n",
    "        'a_MM_dehydration': a_MM_list_dehydration,\n",
    "        'theta_MM_dehydration': theta_MM_list_dehydration,\n",
    "        'a_ML_dehydration': a_ML_list_dehydration,\n",
    "        'theta_ML_dehydration': theta_ML_list_dehydration\n",
    "        })\n",
    "    \n",
    "    return gamma_parameter_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex attention \n",
    "#### Hypothesis\n",
    "We expect the selective attention accuracy and response time to decrease under the influence of dehydration. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flanker Test\n",
    "In this section, first we investigate the distribution type, then find some of its features. Finally, implement statistical test to approve or dis approve its hypothesis.\n",
    "##### Response Time\n",
    "response time is supposed to increase under the dehydration condition. To investigate this assumption, first the type of distribution is determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sketch Flanker histogtam for raw data\n",
    "render_plot(test='flanker', data_type= 'raw response data', plot_type='histogram')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the histogram of raw Flanker test data for response time shows that approximately all the participant data is distributed with a Gamma distribution pattern. Next, Q_Q plot is utilized to investigate this assumption. The mentioned plot can be sketched based on Maximum Likelihood approach or Robust method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sketch Q_Q plot on the Maximum Likelihood method \n",
    "render_plot(test='flanker', data_type= 'raw response data', plot_type='Q_Q plot ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sketch Q_Q plot on the Robust method \n",
    "render_plot(test='flanker', data_type= 'raw response data', plot_type='Q_Q plot robust')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Q_Q plots confirm the assumption about the data distribution pattern. Consequently, the mentioned distributions can be evaluated with Method of Moments (MM) and Maximum Likelihood (ML) methods. Below, $a$ and $\\theta$ parameters for the mentioned methods are calculated.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a tabel from a and theta parameters of MM and ML\n",
    "gamma_parameters_df = making_gamma_parameters_tabel('flanker', 'raw response data', stat_df)\n",
    "gamma_parameters_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly, based on the data distribution, two statistical tests (2-sample t-test and Wilcoxon signed-rank test) are implemented to evaluate the hypothesis. First, 2-sample t-test can be implemented on the data sets as t test is the best nominate when there is sparse information about the sample. Second, Wilcoxon signed-rank test can be utilized since the control and dehydration data sets for each person are homogonous in terms of their shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a tabel of 2_sample t_test and wilcoxon test\n",
    "statistical_test_df = statistical_test('flanker', 'raw response data', stat_df)\n",
    "statistical_test_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Blue and Green participants the hypothesis is rejected. Also, even though Wilcoxon p value is less than $\\alpha$ = 0.05, the p value of the t test is quite more than the $\\alpha$ value. It shows that this two distributions share almost the same shape, but the response time did not increase during the hydration experiment. Consequently, the hypothesis is rejected for the mentioned participants. However, Pink is the only participant who has greater response time after imposing the dehydration condition. Therefore, the hypothesis is approved for the mentioned participant. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy\n",
    "Acurracy is supposed to decrease under the dehydration condition. To investigate this assumption, first the type of distribution is determined.\n",
    "Acurracy data set consist of two values: correct and incorrect. Consequently, we can consider the mentioned data set as a binomial distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sketch Flanker binomial plot for error dat \n",
    "render_plot(test='flanker', data_type= 'error', plot_type='binomial plot')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binomial distributions can be estimated by a Normal Distribution if $k$ * $p$ > 0.05 and $k$ * (1-$p$) > 5. Otherwise, it can be estimated by a Poisson Distribution (Bagui & Mehra 2017). Below, $p$ and $k$ parameters for each binomial distribution is calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a tabel for binomial parameters\n",
    "binomial_parameters = making_binomial_tabel('flanker', 'error', stat_df)\n",
    "binomial_parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly, based on the data distribution, one statistical test (2-sample z-test for proportion) is implemented to evaluate the hypothesis. the mentioned test can be used for binomial distributions to investigate the hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a tabel of two sample z test for proportion\n",
    "statistical_test_df = statistical_test('flanker', 'error', stat_df)\n",
    "statistical_test_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the majority of the participants (Green, Orange, Pink, and Red) no significant change in the number of errors  is detected, so the hypothesis is rejected for them. However, dehydration affected the accuracy of the participant Blue. Thus, the hypothesis is approved for the mentioned participant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b91fa5cffef32cb10787a50fea9666676a7951181e01280b4644cd70c964bf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
