{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HydroHomies Plots\n",
    "In this notebook, the plots, figures and also some explanations or details about each of them are being presented.  \n",
    "\n",
    "To clarify plots, please follow this order:\n",
    "- Title for each plot is mandatory\n",
    "- Analysis must be written \n",
    "- legends are manedatory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "with open('config.yaml') as stream:\n",
    "    config = yaml.safe_load(stream)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "code1"
    ]
   },
   "source": [
    "### Cleaning (Digit Span Raw Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_digit_span(raw_df):\n",
    "    # Select the sequence length data from the raw data and create a dataframe\n",
    "    seq_length_df = raw_df[raw_df[1].astype(str).str.match(r'\\d+')]\n",
    "\n",
    "    # Get the value of the longest sequence remembered\n",
    "    longest = seq_length_df[2]\n",
    "    longest = longest.tolist()\n",
    "\n",
    "    # Get the number of errors made\n",
    "    error_number = seq_length_df[3]\n",
    "    error_number = error_number.tolist()\n",
    "\n",
    "    # Select the rows with the click stimulus data\n",
    "    click_stim_df = raw_df[raw_df[1]=='clickedStim']\n",
    "    click_stim_df.size\n",
    "\n",
    "    # Calculate the number of clicks made by the participant\n",
    "    clicks_observed = click_stim_df.count(axis=1) - 2 \n",
    "    clicks_observed = clicks_observed.tolist()\n",
    "\n",
    "    # Calculate the number of clicks that the participant should have made\n",
    "    clicks_expected =  pd.to_numeric(longest) + 1\n",
    "    clicks_expected = clicks_expected.tolist()\n",
    "\n",
    "    # Create a new dataframe with all the values calculated above\n",
    "    clean_data = pd.DataFrame(data ={'seq length':longest,\n",
    "                        'errors': error_number,\n",
    "                        'clicks expected': clicks_expected,\n",
    "                        'clicks observed':clicks_observed})\n",
    "\n",
    "    # Return the new dataframe\n",
    "    return clean_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Integration For Each Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merged_df(config_dict):\n",
    "    data_dict = {}\n",
    "\n",
    "    # read the files \n",
    "    for test, file in config_dict.items():\n",
    "        df_dict = pd.read_excel(file, sheet_name=None, header=None)\n",
    "\n",
    "        for session, df in df_dict.items():\n",
    "\n",
    "            # extracting the participant name and type name\n",
    "            participant = test.split('_')[-1]\n",
    "            test_name = test.split('_')[0]\n",
    "\n",
    "            #extracting repeat number and making its column except for personal\n",
    "            try:\n",
    "                type, repeat = session.split('_')\n",
    "                df.insert(0, 'repeat', repeat)\n",
    "\n",
    "            except ValueError:\n",
    "                type = session\n",
    "\n",
    "\n",
    "            #cleaning digit_span row data\n",
    "            if test_name == 'digit':\n",
    "                df = clean_digit_span(df.iloc[3:])\n",
    "            \n",
    "            # verbal fluency test contains header\n",
    "            elif test_name =='verbal':\n",
    "                df = df.iloc[1:]\n",
    "\n",
    "            # inserting the type and participant columns\n",
    "            df.insert(0, 'type', type)\n",
    "            df.insert(0, 'participant', participant)\n",
    " \n",
    "            # concatenating data frames of each test\n",
    "            if test_name not in data_dict:\n",
    "                data_dict[test_name] = df\n",
    "            else:\n",
    "                data_dict[test_name] = pd.concat([data_dict[test_name], df])\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function\n",
    "df_dict = create_merged_df(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flanker Test Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flanker_dataframe():\n",
    "    data_dict = create_merged_df(config)\n",
    "    flanker_df = data_dict[\"flanker\"]\n",
    "    flanker_df.rename(columns={0: \"pattern\", 1: \"expression\", 2: \"correctness\", 3: \"response-time\"}, inplace=True)\n",
    "    flanker_df[\"correctness\"] = flanker_df[\"correctness\"].replace(1, \"correct\")\n",
    "    flanker_df[\"correctness\"] = flanker_df[\"correctness\"].replace(2, \"incorrect\")\n",
    "    flanker_df[\"correctness\"] = flanker_df[\"correctness\"].replace(3, \"not-answer\")\n",
    "    return flanker_df\n",
    "\n",
    "flanker_df = create_flanker_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.transform import dodge, factor_cmap\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, FactorRange\n",
    "import panel as pn\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()\n",
    "pn.extension()\n",
    "\n",
    "def flanker_plot(answer_type=\"correct\"):  # Roya\n",
    "    \n",
    "    flanker_df = create_flanker_dataframe()\n",
    "    flanker_df = flanker_df[flanker_df[\"correctness\"] == answer_type]\n",
    "\n",
    "    flanker_df = flanker_df.groupby([\"participant\", \"type\", \"repeat\"])[\n",
    "        \"correctness\"].count().reset_index()\n",
    "    df = flanker_df.groupby(by=[\"participant\", \"type\"])[\n",
    "        \"correctness\"].mean()\n",
    "    dehydration = flanker_df[flanker_df[\"type\"] == \"dehydration\"]\n",
    "    control = flanker_df[flanker_df[\"type\"] == \"control\"]\n",
    "\n",
    "    index_cmap = factor_cmap('x', palette=[\"salmon\", \"skyblue\"], factors=[\"dehydration\", \"control\"], start=1, end=2)\n",
    "    data = {\n",
    "        'x': list(df.index.values),\n",
    "        'counts': sum(zip(control[\"correctness\"].tolist(), dehydration[\"correctness\"].tolist()), ())\n",
    "        }\n",
    "\n",
    "    source = ColumnDataSource(data=data)\n",
    "    p = figure(x_range=FactorRange(*list(df.index.values)), y_range=(0, 50), height=400, title=f\"Average of {answer_type} answers\",\n",
    "               toolbar_location=None, tools=\"\", y_axis_label=\"counts\")\n",
    "\n",
    "    p.vbar(x='x', top='counts', width=0.9, source=source, fill_color=index_cmap)\n",
    "\n",
    "    p.y_range.start = 0\n",
    "    p.x_range.range_padding = 0.1\n",
    "    p.xaxis.major_label_orientation = 1\n",
    "    p.xgrid.grid_line_color = None\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "answer_types =['correct','incorrect']\n",
    "inter_plot = pn.interact(flanker_plot, answer_type = answer_types)\n",
    "inter_plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stroop Test  Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stroop_test(): # Mahdiye\n",
    "    total_dict = create_merged_df(config)\n",
    "    stroop_df = total_dict['stroop']\n",
    "    stroop_df.drop(stroop_df.columns[[3,7]], axis=1, inplace=True)\n",
    "    stroop_df = stroop_df.set_axis(['participant', 'type','repeat','word name','word color',\n",
    "                                    'name_color match','pressed _key','status','reaction_time'], axis=1)\n",
    "    stroop_df['type&repeat'] = stroop_df['type']+stroop_df['repeat']\n",
    "    return stroop_df\n",
    "\n",
    "stroop_df = stroop_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, Whisker\n",
    "import panel as pn\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_stroop_bar_plot(participant='blue'):\n",
    "    df = stroop_df[stroop_df['participant']==participant]\n",
    "    \n",
    "    dff= df.groupby('type&repeat').min().reset_index()\n",
    "    p = figure(x_range=dff['type&repeat'], height=350, toolbar_location=None, \n",
    "               title=f'Stroop Test {participant}', y_axis_label=\"Reaction time(milliseconds)\")\n",
    "    p.vbar(x=dff['type&repeat'], bottom=0,top=dff['reaction_time'], width=0.5, line_color='white', color=participant)\n",
    "    return p\n",
    "\n",
    "#interactive plots\n",
    "participants_color =['blue','red','orange','green','pink']\n",
    "inter_plot = pn.interact(individual_stroop_bar_plot, participant = participants_color)\n",
    "inter_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_stroop_box_plot(participant):\n",
    "    \n",
    "    df = stroop_df[stroop_df['participant']==participant]\n",
    "    kinds = df['type&repeat'].unique()\n",
    "    \n",
    "    # compute quantiles\n",
    "    qs = df.groupby('type&repeat').reaction_time.quantile([0.25, 0.5, 0.75])\n",
    "    qs = qs.unstack().reset_index()\n",
    "    qs.columns = ['type&repeat', \"q1\", \"q2\", \"q3\"]\n",
    "    df = pd.merge(df, qs, on='type&repeat', how=\"left\")\n",
    "\n",
    "    # compute IQR outlier bounds\n",
    "    iqr = df.q3 - df.q1\n",
    "    df[\"upper\"] = df.q3 + 1.5*iqr\n",
    "    df[\"lower\"] = df.q1 - 1.5*iqr\n",
    "\n",
    "    source = ColumnDataSource(df)\n",
    "\n",
    "    p = figure(x_range=kinds,y_range=[0,stroop_df['reaction_time'].max() * 1.3],tools=\"\", toolbar_location=None,\n",
    "                title=\"box plot of stroop test \"+participant,\n",
    "               background_fill_color=\"#eaefef\", y_axis_label=\"Reaction time(milliseconds)\")\n",
    "\n",
    "\n",
    "    # outlier range\n",
    "    whisker = Whisker(base='type&repeat', upper=\"upper\", lower=\"lower\", source=source)\n",
    "    whisker.upper_head.size = whisker.lower_head.size = 20\n",
    "    p.add_layout(whisker)\n",
    "\n",
    "    # quantile boxes\n",
    "    p.vbar('type&repeat', 0.5, \"q2\", \"q3\", color = participant,bottom=0, source=source, line_color=\"black\")\n",
    "    p.vbar('type&repeat', 0.5, \"q1\", \"q2\", color=participant, bottom=0, source=source, line_color=\"black\")\n",
    "    \n",
    "    # outliers\n",
    "    outliers = df[~df.reaction_time.between(df.lower, df.upper)]\n",
    "    p.scatter('type&repeat', 'reaction_time', source=outliers, size=6, color=\"black\", alpha=0.5)\n",
    "\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.major_label_text_font_size=\"14px\"\n",
    "    p.axis.axis_label_text_font_size=\"12px\"\n",
    "\n",
    "    return p\n",
    "    \n",
    "#interactive plots\n",
    "participants_color =['blue','red','orange','green','pink']\n",
    "inter_plot = pn.interact(individual_stroop_box_plot, participant = participants_color)\n",
    "inter_plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Signal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_test(stop_df): # Jacob\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbal Fluency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbal_test(verbal_df): # Jacob\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit Span Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def digit_test(digit_df): # Karina\n",
    "#     pass\n",
    "df_dict[\"digit\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
